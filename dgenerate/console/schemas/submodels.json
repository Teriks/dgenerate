{"UNet": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "quantizer": {"optional": true, "types": ["str"], "default": null}, "HELP": "Specify a UNet using a URI.\n\nExamples:\n\n\"huggingface/unet\", \"huggingface/unet;revision=main\", \"unet_folder_on_disk\"\n\nThe \"revision\" argument specifies the model revision to use for the UNet when loading from Hugging\nFace repository, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the UNet model variant. If \"variant\" is specified when loading from\na Hugging Face repository or folder, weights will be loaded from \"variant\" filename, e.g.\n\"pytorch_model.<variant>.safetensors. For this argument, \"variant\" defaults to the value of\n--variant if it is not specified in the URI.\n\nThe \"subfolder\" argument specifies the UNet model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder. If you are loading from a\ncombined single file checkpoint containing multiple components, this value will be used to determine\nthe key in the checkpoint that contains the unet, by default \"unet\" is used if subfolder is not\nprovided.\n\nThe \"dtype\" argument specifies the UNet model precision, it defaults to the value of -t/--dtype and\nshould be one of: auto, bfloat16, float16, or float32.\n\nThe \"quantizer\" argument specifies a quantization backend and configuration for the UNet model\nindividually, and uses the same URI syntax as --quantizer. If working from the command line you may\nneed to nested quote this URI, i.e:\n\n--unet 'huggingface/unet;quantizer=\"bnb;bits=8\"'\n\nIf you wish to load weights directly from a path on disk, you must point this argument at the folder\nthey exist in, which should also contain the config.json file for the UNet. For example, a\ndownloaded repository folder from Hugging Face."}, "Transformer": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "quantizer": {"optional": true, "types": ["str"], "default": null}, "HELP": "Specify a Stable Diffusion 3 or Flux Transformer model using a URI.\n\nExamples:\n\n\"huggingface/transformer\"\n\"huggingface/transformer;revision=main\"\n\"transformer_folder_on_disk\"\n\nBlob links / single file loads are supported for SD3 Transformers.\n\nThe \"revision\" argument specifies the model revision to use for the Transformer when loading from\nHugging Face repository or blob link, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the Transformer model variant. If \"variant\" is specified when\nloading from a Hugging Face repository or folder, weights will be loaded from \"variant\" filename,\ne.g. \"pytorch_model.<variant>.safetensors. For this argument, \"variant\" defaults to the value of\n--variant if it is not specified in the URI.\n\nThe \"subfolder\" argument specifies the Transformer model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the Transformer model precision, it defaults to the value of\n-t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nThe \"quantizer\" argument specifies a quantization backend and configuration for the Transformer\nmodel individually, and uses the same URI syntax as --quantizer. If working from the command line\nyou may need to nested quote this URI, i.e:\n\n--transformer 'huggingface/transformer;quantizer=\"bnb;bits=8\"'\n\nIf you wish to load a weights file directly from disk, the simplest way is: --transformer\n\"transformer.safetensors\", or with a dtype \"transformer.safetensors;dtype=float16\". All loading\narguments except \"dtype\" and \"quantizer\" are unused in this case and may produce an error message if\nused.\n\nIf you wish to load a specific weight file from a Hugging Face repository, use the blob link loading\nsyntax: --transformer\n\"AutoencoderKL;https://huggingface.co/UserName/repository-name/blob/main/transformer.safetensors\",\nthe \"revision\" argument may be used with this syntax."}, "Text Encoder": {"encoder": {"optional": false, "types": ["str"], "options": ["CLIPTextModel", "CLIPTextModelWithProjection", "T5EncoderModel", "DistillT5EncoderModel", "ChatGLMModel"]}, "model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["auto", "float16", "bfloat16", "float32"]}, "quantizer": {"optional": true, "types": ["str"], "default": null}, "mode": {"optional": true, "types": ["str"], "default": null, "options": ["clip-l", "clip-l-sd3", "clip-g-sd3", "clip-l-sd35-large", "clip-g-sd35-large", "t5-xxl", "t5-xxl-sd3"]}, "HELP": "Specify Text Encoders for the main model using URIs, main models may use one or more text encoders\ndepending on the --model-type value and other dgenerate arguments. See: --text-encoders help for\ninformation about what text encoders are needed for your invocation.\n\nExamples:\n\n\"CLIPTextModel;model=huggingface/text_encoder\"\n\"CLIPTextModelWithProjection;model=huggingface/text_encoder;revision=main\"\n\"T5EncoderModel;model=text_encoder_folder_on_disk\"\n\"DistillT5EncoderModel;model=text_encoder_folder_on_disk\"\n\nFor main models which require multiple text encoders, the + symbol may be used to indicate that a\ndefault value should be used for a particular text encoder, for example: --text-encoders + +\nhuggingface/encoder3. Any trailing text encoders which are not specified are given their default\nvalue.\n\nThe value \"null\" may be used to indicate that a specific text encoder should not be loaded.\n\nThe \"revision\" argument specifies the model revision to use for the Text Encoder when loading from\nHugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the Text Encoder model variant. If \"variant\" is specified when\nloading from a Hugging Face repository or folder, weights will be loaded from \"variant\" filename,\ne.g. \"pytorch_model.<variant>.safetensors\". For this argument, \"variant\" defaults to the value of\n--variant if it is not specified in the URI.\n\nThe \"subfolder\" argument specifies the Text Encoder model subfolder, if specified when loading from\na Hugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the Text Encoder model precision, it defaults to the value of\n-t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nThe \"quantizer\" URI argument can be used to specify a quantization backend for the text encoder\nusing the same URI syntax as --quantizer. This is supported when loading from Hugging Face repo\nslugs / folders on disk, and when using the \"mode\" argument with monolithic (non-sharded)\ncheckpoints. This is not supported when loading a submodule out of a combined checkpoint file with\n\"subfolder\". If working from the command line you may need to nested quote this URI, i.e:\n\n--text-encoders 'CLIPTextModel;model=huggingface/text_encoder;quantizer=\"bnb;bits=8\"'\n\nThe \"mode\" argument can be used to load monolithic single file checkpoints with specific\narchitecture configurations. Available modes are:\n\nFlux & T5 universal modes:\n\n* \"clip-l\" for monolithic Flux CLIP-L checkpoints\n* \"t5-xxl\" for monolithic Flux T5 checkpoints\n\nSD3 and SD3.5 specific modes:\n\n* \"clip-l-sd3\" for SD3/SD3.5 medium CLIP-L checkpoints\n* \"clip-g-sd3\" for SD3/SD3.5 medium CLIP-G checkpoints\n* \"t5-xxl-sd3\" for SD3/SD3.5 T5-XXL checkpoints\n* \"clip-l-sd35-large\" for SD3.5 large variant CLIP-L checkpoints\n* \"clip-g-sd35-large\" for SD3.5 large variant CLIP-G checkpoints\n\n The \"mode\" option is mutually exclusive with \"subfolder\".\n\nAvailable encoder classes are:\n\n* CLIPTextModel\n* CLIPTextModelWithProjection\n* T5EncoderModel\n* DistillT5EncoderModel (see: LifuWang/DistillT5)\n* ChatGLMModel (for Kolors models)\n\nIf you wish to load weights directly from a path on disk, you must point this argument at the folder\nthey exist in, which should also contain the config.json file for the Text Encoder. For example, a\ndownloaded repository folder from Hugging Face."}, "VAE": {"encoder": {"optional": false, "types": ["str"], "options": ["AutoencoderKL", "AsymmetricAutoencoderKL", "AutoencoderTiny", "ConsistencyDecoderVAE"]}, "model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "extract": {"optional": false, "types": ["bool"], "default": false}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "HELP": "Specify a VAE using a URI, the URI syntax is: \"AutoEncoderClass;model=(Hugging Face repository\nslug/blob link or file/folder path)\".\n\nExamples:\n\n\"AutoencoderKL;model=vae.pt\"\n\"AsymmetricAutoencoderKL;model=huggingface/vae\"\n\"AutoencoderTiny;model=huggingface/vae\"\n\"ConsistencyDecoderVAE;model=huggingface/vae\"\n\nThe AutoencoderKL encoder class accepts Hugging Face repository slugs/blob links, .pt, .pth, .bin,\n.ckpt, and .safetensors files.\n\nOther encoders can only accept Hugging Face repository slugs/blob links, or a path to a folder on\ndisk with the model configuration and model file(s).\n\nIf an AutoencoderKL VAE model file exists at a URL which serves the file as a raw download, you may\nprovide an http/https link to it and it will be downloaded to dgenerate's web cache.\n\nAside from the \"model\" argument, there are four other optional arguments that can be specified,\nthese are: \"revision\", \"variant\", \"subfolder\", \"dtype\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"AutoencoderKL;model=huggingface/vae;revision=main;variant=fp16;subfolder=sub_folder;dtype=float16\"\n\nThe \"revision\" argument specifies the model revision to use for the VAE when loading from Hugging\nFace repository or blob link, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the VAE model variant. If \"variant\" is specified when loading from\na Hugging Face repository or folder, weights will be loaded from \"variant\" filename, e.g.\n\"pytorch_model.<variant>.safetensors. \"variant\" in the case of --vae does not default to the value\nof --variant to prevent failures during common use cases.\n\nThe \"subfolder\" argument specifies the VAE model subfolder, if specified when loading from a Hugging\nFace repository or folder, weights from the specified subfolder.\n\nThe \"extract\" argument specifies that \"model\" points at a combind single file checkpoint containing\nmultiple components such as the UNet and Text Encoders, and that we should extract the VAE. When\nusing this argument you can use \"subfolder\" to indicate the key in the checkpoint containing the\nmodel, this defaults to \"vae\".\n\nThe \"dtype\" argument specifies the VAE model precision, it defaults to the value of -t/--dtype and\nshould be one of: auto, bfloat16, float16, or float32.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --vae\n\"AutoencoderKL;my_vae.safetensors\", or with a dtype\n\"AutoencoderKL;my_vae.safetensors;dtype=float16\". All loading arguments except \"dtype\" are unused in\nthis case and may produce an error message if used.\n\nIf you wish to load a specific weight file from a Hugging Face repository, use the blob link loading\nsyntax: --vae\n\"AutoencoderKL;https://huggingface.co/UserName/repository-name/blob/main/vae_model.safetensors\", the\n\"revision\" argument may be used with this syntax."}, "Image Encoder": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "HELP": "Specify an Image Encoder using a URI.\n\nImage Encoders are used with --ip-adapters models, and must be specified if none of the loaded\n--ip-adapters contain one. An error will be produced in this situation, which requires you to use\nthis argument.\n\nAn image encoder can also be manually specified for Stable Cascade models.\n\nExamples:\n\n\"huggingface/image_encoder\"\n\"huggingface/image_encoder;revision=main\"\n\"image_encoder_folder_on_disk\"\n\nBlob links / single file loads are not supported for Image Encoders.\n\nThe \"revision\" argument specifies the model revision to use for the Image Encoder when loading from\nHugging Face repository or blob link, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the Image Encoder model variant. If \"variant\" is specified when\nloading from a Hugging Face repository or folder, weights will be loaded from \"variant\" filename,\ne.g. \"pytorch_model.<variant>.safetensors.\n\nSimilar to --vae, \"variant\" does not default to the value of --variant in order to prevent errors\nwith common use cases. If you specify multiple IP Adapters, they must all have the same \"variant\"\nvalue or you will receive a usage error.\n\nThe \"subfolder\" argument specifies the Image Encoder model subfolder, if specified when loading from\na Hugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the Image Encoder model precision, it defaults to the value of\n-t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nIf you wish to load weights directly from a path on disk, you must point this argument at the folder\nthey exist in, which should also contain the config.json file for the Image Encoder. For example, a\ndownloaded repository folder from Hugging Face."}, "LoRA": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "scale": {"optional": false, "types": ["float"], "default": 1.0}, "HELP": "Specify one or more LoRA models using URIs. These should be a Hugging Face repository slug / blob\nlink, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or .safetensors file), or\nmodel folder containing model files.\n\nIf a LoRA model file exists at a URL which serves the file as a raw download, you may provide an\nhttp/https link to it and it will be downloaded to dgenerate's web cache.\n\nOptional arguments can be provided after a LoRA model specification, these are: \"scale\", \"revision\",\n\"subfolder\", and \"weight-name\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/lora;scale=1.0;revision=main;subfolder=repo_subfolder;weight-name=lora.safetensors\"\n\nThe \"scale\" argument indicates the scale factor of the LoRA.\n\nThe \"revision\" argument specifies the model revision to use for the LoRA when loading from Hugging\nFace repository, (The Git branch / tag, default is \"main\").\n\nThe \"subfolder\" argument specifies the LoRA model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"weight-name\" argument indicates the name of the weights file to be loaded when loading from a\nHugging Face repository or folder on disk.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --loras\n\"my_lora.safetensors\", or with a scale \"my_lora.safetensors;scale=1.0\", all other loading arguments\nare unused in this case and may produce an error message if used."}, "IP Adapter": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "scale": {"optional": false, "types": ["float"], "default": 1.0}, "HELP": "Specify one or more IP Adapter models using URIs. These should be a Hugging Face repository slug /\nblob link, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or .safetensors file),\nor model folder containing model files.\n\nIf an IP Adapter model file exists at a URL which serves the file as a raw download, you may provide\nan http/https link to it and it will be downloaded to dgenerate's web cache.\n\nOptional arguments can be provided after an IP Adapter model specification, these are: \"scale\",\n\"revision\", \"subfolder\", and \"weight-name\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/ip-adapter;scale=1.0;revision=main;subfolder=repo_subfolder;weight-name=ip_adapter.safetensors\".\n\nThe \"scale\" argument indicates the scale factor of the IP Adapter.\n\nThe \"revision\" argument specifies the model revision to use for the IP Adapter when loading from\nHugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"subfolder\" argument specifies the IP Adapter model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"weight-name\" argument indicates the name of the weights file to be loaded when loading from a\nHugging Face repository or folder on disk.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --ip-adapters\n\"ip_adapter.safetensors\", or with a scale \"ip_adapter.safetensors;scale=1.0\", all other loading\narguments are unused in this case and may produce an error message if used."}, "Control Net": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"]}, "variant": {"optional": true, "types": ["str"]}, "subfolder": {"optional": true, "types": ["str"]}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "scale": {"optional": false, "types": ["float"], "default": 1.0}, "start": {"optional": false, "types": ["float"], "default": 0.0}, "end": {"optional": false, "types": ["float"], "default": 1.0}, "mode": {"optional": true, "types": ["int", "str"], "default": null}, "HELP": "Specify one or more ControlNet models using URIs. This should be a Hugging Face repository slug /\nblob link, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or .safetensors file),\nor model folder containing model files.\n\nIf a ControlNet model file exists at a URL which serves the file as a raw download, you may provide\nan http/https link to it and it will be downloaded to dgenerate's web cache.\n\nOptional arguments can be provided after the ControlNet model specification, these are: \"scale\",\n\"start\", \"end\", \"mode\", \"revision\", \"variant\", \"subfolder\", and \"dtype\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/controlnet;scale=1.0;start=0.0;end=1.0;revision=main;variant=fp16;subfolder=repo_subfolder;dtype=float16\".\n\nThe \"scale\" argument specifies the scaling factor applied to the ControlNet model, the default value\nis 1.0.\n\nThe \"start\" argument specifies at what fraction of the total inference steps to begin applying the\nControlNet, defaults to 0.0, IE: the very beginning.\n\nThe \"end\" argument specifies at what fraction of the total inference steps to stop applying the\nControlNet, defaults to 1.0, IE: the very end.\n\nThe \"mode\" argument can be used when using --model-type sdxl / flux and a ControlNet Union model to\nspecify the ControlNet mode. This may be a string or an integer.\n\nFor --model-type sdxl Acceptable \"mode\" values are:\n\n    \"openpose\" = 0\n    \"depth\" = 1\n    \"hed\" = 2\n    \"pidi\" = 2\n    \"scribble\" = 2\n    \"ted\" = 2\n    \"canny\" = 3\n    \"lineart\" = 3\n    \"anime_lineart\" = 3\n    \"mlsd\" = 3\n    \"normal\" = 4\n    \"segment\" = 5\n\n\nFor --model-type flux Acceptable \"mode\" values are:\n\n    \"canny\" = 0\n    \"tile\" = 1\n    \"depth\" = 2\n    \"blur\" = 3\n    \"pose\" = 4\n    \"gray\" = 5\n    \"lq\" = 6\n\nThe \"revision\" argument specifies the model revision to use for the ControlNet model when loading\nfrom Hugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the ControlNet model variant, if \"variant\" is specified when\nloading from a Hugging Face repository or folder, weights will be loaded from \"variant\" filename,\ne.g. \"pytorch_model.<variant>.safetensors. \"variant\" defaults to automatic selection. \"variant\" in\nthe case of --control-nets does not default to the value of --variant to prevent failures during\ncommon use cases.\n\nThe \"subfolder\" argument specifies the ControlNet model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the ControlNet model precision, it defaults to the value of\n-t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --control-nets\n\"my_controlnet.safetensors\" or --control-nets \"my_controlnet.safetensors;scale=1.0;dtype=float16\",\nall other loading arguments aside from \"scale\", \"start\", \"end\", and \"dtype\" are unused in this case\nand may produce an error message if used.\n\nIf you wish to load a specific weight file from a Hugging Face repository, use the blob link loading\nsyntax: --control-nets\n\"https://huggingface.co/UserName/repository-name/blob/main/controlnet.safetensors\", the \"revision\"\nargument may be used with this syntax."}, "T2I Adapter": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"]}, "variant": {"optional": true, "types": ["str"]}, "subfolder": {"optional": true, "types": ["str"]}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "scale": {"optional": false, "types": ["float"], "default": 1.0}, "HELP": "Specify one or more T2IAdapter models using URIs. This should be a Hugging Face repository slug /\nblob link, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or .safetensors file),\nor model folder containing model files.\n\nIf a T2IAdapter model file exists at a URL which serves the file as a raw download, you may provide\nan http/https link to it and it will be downloaded to dgenerate's web cache.\n\nOptional arguments can be provided after the T2IAdapter model specification, these are: \"scale\",\n\"revision\", \"variant\", \"subfolder\", and \"dtype\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/t2iadapter;scale=1.0;revision=main;variant=fp16;subfolder=repo_subfolder;dtype=float16\".\n\nThe \"scale\" argument specifies the scaling factor applied to the T2IAdapter model, the default value\nis 1.0.\n\nThe \"revision\" argument specifies the model revision to use for the T2IAdapter model when loading\nfrom Hugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the T2IAdapter model variant, if \"variant\" is specified when\nloading from a Hugging Face repository or folder, weights will be loaded from \"variant\" filename,\ne.g. \"pytorch_model.<variant>.safetensors. \"variant\"  defaults to automatic selection. \"variant\" in\nthe case of --t2i-adapters does not default to the value of --variant to prevent failures during\ncommon use cases.\n\nThe \"subfolder\" argument specifies the ControlNet model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the T2IAdapter model precision, it defaults to the value of\n-t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --t2i-adapters\n\"my_t2i_adapter.safetensors\" or --t2i-adapters \"my_t2i_adapter.safetensors;scale=1.0;dtype=float16\",\nall other loading arguments aside from \"scale\" and \"dtype\" are unused in this case and may produce\nan error message if used.\n\nIf you wish to load a specific weight file from a Hugging Face repository, use the blob link loading\nsyntax: --t2i-adapters\n\"https://huggingface.co/UserName/repository-name/blob/main/t2i_adapter.safetensors\", the \"revision\"\nargument may be used with this syntax."}, "Textual Inversion": {"model": {"optional": false, "types": ["str"]}, "token": {"optional": true, "types": ["str"], "default": null}, "revision": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "HELP": "Specify one or more Textual Inversion models using URIs. These should be a Hugging Face repository\nslug / blob link, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or .safetensors\nfile), or model folder containing model files.\n\nIf a Textual Inversion model file exists at a URL which serves the file as a raw download, you may\nprovide an http/https link to it and it will be downloaded to dgenerate's web cache.\n\nOptional arguments can be provided after the Textual Inversion model specification, these are:\n\"token\", \"revision\", \"subfolder\", and \"weight-name\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/ti_model;revision=main;subfolder=repo_subfolder;weight-name=ti_model.safetensors\".\n\nThe \"token\" argument can be used to override the prompt token used for the textual inversion prompt\nembedding. For normal Stable Diffusion the default token value is provided by the model itself, but\nfor Stable Diffusion XL and Flux the default token value is equal to the model file name with no\nextension and all spaces replaced by underscores.\n\nThe \"revision\" argument specifies the model revision to use for the Textual Inversion model when\nloading from Hugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"subfolder\" argument specifies the Textual Inversion model subfolder, if specified when loading\nfrom a Hugging Face repository or folder, weights from the specified subfolder.\n\nThe \"weight-name\" argument indicates the name of the weights file to be loaded when loading from a\nHugging Face repository or folder on disk.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --textual-inversions\n\"my_ti_model.safetensors\", all other loading arguments are unused in this case and may produce an\nerror message if used."}, "Adetailer Detector": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "confidence": {"optional": false, "types": ["float"], "default": 0.3}, "detector-padding": {"optional": true, "types": ["int", "tuple"], "default": null}, "mask-shape": {"optional": true, "types": ["str"], "default": null, "options": ["r", "rect", "rectangle", "c", "circle", "ellipse"]}, "mask-padding": {"optional": true, "types": ["int", "tuple"], "default": null}, "mask-blur": {"optional": true, "types": ["int"], "default": null}, "mask-dilation": {"optional": true, "types": ["int"], "default": null}, "model-masks": {"optional": true, "types": ["bool"], "default": null}, "index-filter": {"optional": true, "types": ["list"], "default": null}, "class-filter": {"optional": true, "types": ["list"], "default": null}, "prompt": {"optional": true, "types": ["str"], "default": null}, "negative-prompt": {"optional": true, "types": ["str"], "default": null}, "device": {"optional": true, "types": ["str"], "default": null}, "HELP": "Specify one or more adetailer YOLO detector model URIs. When specifying this option, you must\nprovide an image to --image-seeds, inpaint masks will be auto generated based on what is detected by\nthe provided detector models.\n\nThe models will be used in sequence to detect and then inpaint your image within the detection\nareas. This can be used for face detailing, face swapping, hand detailing, etc. on any arbitrary\nimage provided using an image generation model of your choice.\n\nThis option supports: --model-type sd, sdxl, kolors, sd3, flux, and flux-fill\n\nExample: --adetailer-detectors Bingsu/adetailer;weight-name=face_yolov8n.pt\n\nThe \"revision\" argument specifies the model revision to use for the adetailer model when loading\nfrom Hugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"subfolder\" argument specifies the adetailer model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"weight-name\" argument indicates the name of the weights file to be loaded when loading from a\nHugging Face repository or folder on disk.\n\nThe \"class-filter\" (overrides --adetailer-class-filter) argument is a list of class IDs or class\nnames that indicates what YOLO detection classes to keep. This filter is applied first, before\nindex-filter. Detections that don't match any of the specified classes will be ignored.\n\nExample \"class-filter\" values:\n\n    * Only keep detection class ID 0:\n    class-filter=0\n\n    * Only keep detection class \"hand\":\n    class-filter=hand\n\n    * Keep class IDs 2 and 3:\n    class-filter=2,3\n\n    * Keep class ID 0 and class name \"hand\":\n    class-filter=0,hand\n\n    * String digits are interpreted as integers:\n    class-filter=\"0\" (interpreted as class name \"0\", not likely useful)\n\n    * List syntax is also supported:\n    class-filter=[0, \"hand\"]\n\nThe \"index-filter\" (overrides --adetailer-index-filter) argument is a list values or a\nsingle value that indicates what YOLO detection indices to keep, the index values start\nat zero. Detections are sorted by their top left bounding box coordinate from left to right,\ntop to bottom, by (confidence descending). The order of detections in the image is identical to\nthe reading order of words on a page (english). Inpainting will only be preformed on the\nspecified detection indices, if no indices are specified, then inpainting\nwill be preformed on all detections. This filter is applied after class-filter.\n\nExample \"index-filter\" values:\n\n    * keep the first, leftmost, topmost detection:\n    index-filter=0\n\n    * keep detections 1 and 3:\n    index-filter=[1, 3]\n\n    * CSV syntax is supported (tuple):\n    index-filter=1,3\n\nThe \"detector-padding\" (overrides --adetailer-detector-paddings) argument specifies the amount of\npadding that will be added to the detection rectangle which is used to generate a masked area. The\ndefault is 0, you can make the mask area around the detected feature larger with positive padding\nand smaller with negative padding.\n\nPadding examples:\n\n    32 (32px Uniform, all sides)\n\n    10x20 (10px Horizontal, 20px Vertical)\n\n    10x20x30x40 (10px Left, 20px Top, 30px Right, 40px Bottom)\n\nThe \"mask-padding\" (overrides --adetailer-mask-paddings) argument indicates how much padding to\nplace around the masked area when cropping out the image to be inpainted. This value must be large\nenough to accommodate any feathering on the edge of the mask caused by \"mask-blur\" or\n\"mask-dilation\" for the best result, the default value is 32. The syntax for specifying this value\nis identical to \"detector-padding\".\n\nThe \"mask-shape\" (overrides --adetailer-mask-shapes) argument indicates what mask shape adetailer\nshould attempt to draw around a detected feature, the default value is \"rectangle\". You may also\nspecify \"circle\" to generate an ellipsoid shaped mask, which might be helpful for achieving better\nblending. Valid values are: (\"r\", \"rect\", \"rectangle\"), or (\"c\", \"circle\", \"ellipse\").\n\nThe \"mask-blur\" (overrides --adetailer-mask-blurs) argument indicates the level of gaussian blur to\napply to the generated inpaint mask, which can help with smooth blending in of the inpainted feature\n\nThe \"model-masks\" (overrides --adetailer-model-masks) argument indicates that masks generated by the\nmodel itself should be preferred over masks generated from the detection bounding box. If this is\nTrue, and the model itself returns mask data, \"mask-shape\", \"mask-padding\", and \"detector-padding\"\nwill all be ignored.\n\nThe \"mask-dilation\" (overrides --adetailer-mask-dilations) argument indicates the amount of dilation\napplied to the inpaint mask, see: cv2.dilate\n\nThe \"confidence\" argument indicates the confidence value to use with the YOLO detector model, this\nvalue defaults to 0.3 if not specified.\n\nThe \"prompt\" (overrides --prompt positive) argument overrides the positive inpainting prompt for\ndetections by this detector.\n\nThe \"negative-prompt\" (overrides --prompt negative) argument overrides the negative inpainting\nprompt for detections by this detector.\n\nThe \"device\" argument indicates a device override for the YOLO detector model, the detector model\ncan be set to run on a different device if desired, for example: cuda:0, cuda:1, cpu, etc. It runs\non the same device as --device by default.\n\nIf you wish to load a weights file directly from disk, use: --adetailer-detectors \"yolo_model.pt\"\n\nYou may also load a YOLO model directly from a URL or Hugging Face blob link.\n\nExample: --adetailer-detectors https://modelsite.com/yolo-model.pt"}, "Stable Cascade Decoder": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "HELP": "Specify a Stable Cascade (s-cascade) decoder model path using a URI. This should be a Hugging Face\nrepository slug / blob link, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or\n.safetensors file), or model folder containing model files.\n\nOptional arguments can be provided after the decoder model specification, these are: \"revision\",\n\"variant\", \"subfolder\", and \"dtype\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/decoder_model;revision=main;variant=fp16;subfolder=repo_subfolder;dtype=float16\".\n\nThe \"revision\" argument specifies the model revision to use for the decoder model when loading from\nHugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the decoder model variant and defaults to the value of --variant.\nWhen \"variant\" is specified when loading from a Hugging Face repository or folder, weights will be\nloaded from \"variant\" filename, e.g. \"pytorch_model.<variant>.safetensors.\n\nThe \"subfolder\" argument specifies the decoder model subfolder, if specified when loading from a\nHugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the Stable Cascade decoder model precision, it defaults to the value\nof -t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --sdxl-refiner\n\"my_decoder.safetensors\" or --sdxl-refiner \"my_decoder.safetensors;dtype=float16\", all other loading\narguments aside from \"dtype\" are unused in this case and may produce an error message if used.\n\nIf you wish to load a specific weight file from a Hugging Face repository, use the blob link loading\nsyntax: --s-cascade-decoder\n\"https://huggingface.co/UserName/repository-name/blob/main/decoder.safetensors\", the \"revision\"\nargument may be used with this syntax."}, "SDXL Refiner": {"model": {"optional": false, "types": ["str"]}, "revision": {"optional": true, "types": ["str"], "default": null}, "variant": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "dtype": {"optional": true, "types": ["str"], "default": null, "options": ["float16", "bfloat16", "float32"]}, "HELP": "Specify a Stable Diffusion XL (sdxl) refiner model path using a URI. This should be a Hugging Face\nrepository slug / blob link, path to model file on disk (for example, a .pt, .pth, .bin, .ckpt, or\n.safetensors file), or model folder containing model files.\n\nOptional arguments can be provided after the SDXL refiner model specification, these are:\n\"revision\", \"variant\", \"subfolder\", and \"dtype\".\n\nThey can be specified as so in any order, they are not positional:\n\n\"huggingface/refiner_model_xl;revision=main;variant=fp16;subfolder=repo_subfolder;dtype=float16\".\n\nThe \"revision\" argument specifies the model revision to use for the refiner model when loading from\nHugging Face repository, (The Git branch / tag, default is \"main\").\n\nThe \"variant\" argument specifies the SDXL refiner model variant and defaults to the value of\n--variant. When \"variant\" is specified when loading from a Hugging Face repository or folder,\nweights will be loaded from \"variant\" filename, e.g. \"pytorch_model.<variant>.safetensors.\n\nThe \"subfolder\" argument specifies the SDXL refiner model subfolder, if specified when loading from\na Hugging Face repository or folder, weights from the specified subfolder.\n\nThe \"dtype\" argument specifies the SDXL refiner model precision, it defaults to the value of\n-t/--dtype and should be one of: auto, bfloat16, float16, or float32.\n\nIf you wish to load a weights file directly from disk, the simplest way is: --sdxl-refiner\n\"my_sdxl_refiner.safetensors\" or --sdxl-refiner \"my_sdxl_refiner.safetensors;dtype=float16\", all\nother loading arguments aside from \"dtype\" are unused in this case and may produce an error message\nif used.\n\nIf you wish to load a specific weight file from a Hugging Face repository, use the blob link loading\nsyntax: --sdxl-refiner\n\"https://huggingface.co/UserName/repository-name/blob/main/refiner_model.safetensors\", the\n\"revision\" argument may be used with this syntax."}}