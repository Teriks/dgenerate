{"adetailer": {"model": {"optional": false, "types": ["str"]}, "prompt": {"optional": false, "types": ["str"]}, "negative-prompt": {"optional": true, "types": ["str"], "default": null}, "prompt-weighter": {"optional": true, "types": ["str"], "default": null}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "revision": {"optional": true, "types": ["str"], "default": null}, "token": {"optional": true, "types": ["str"], "default": null}, "seed": {"optional": true, "types": ["int"], "default": null}, "inference-steps": {"optional": false, "types": ["int"], "default": 30}, "guidance-scale": {"optional": false, "types": ["float"], "default": 5}, "pag-scale": {"optional": true, "types": ["float"], "default": null}, "pag-adaptive-scale": {"optional": true, "types": ["float"], "default": null}, "strength": {"optional": false, "types": ["float"], "default": 0.4}, "detector-padding": {"types": ["int", "str"], "default": 0}, "mask-shape": {"optional": false, "types": ["str"], "default": "rectangle"}, "class-filter": {"optional": true, "types": ["int", "list", "set", "str", "tuple"], "default": null}, "index-filter": {"optional": true, "types": ["int", "list", "set", "tuple"], "default": null}, "mask-padding": {"types": ["int", "str"], "default": 32}, "mask-blur": {"optional": false, "types": ["int"], "default": 4}, "mask-dilation": {"optional": false, "types": ["int"], "default": 4}, "model-masks": {"optional": false, "types": ["bool"], "default": false}, "confidence": {"optional": false, "types": ["float"], "default": 0.3}, "detector-device": {"optional": true, "types": ["str"], "default": null}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "adetailer:\n    arguments:\n        model: str\n        prompt: str\n        negative-prompt: str | None = None\n        prompt-weighter: str | None = None\n        weight-name: str | None = None\n        subfolder: str | None = None\n        revision: str | None = None\n        token: str | None = None\n        seed: int | None = None\n        inference-steps: int = 30\n        guidance-scale: float = 5\n        pag-scale: float | None = None\n        pag-adaptive-scale: float | None = None\n        strength: float = 0.4\n        detector-padding: int | str = 0\n        mask-shape: str = \"rectangle\"\n        class-filter: int | str | list | tuple | set | None = None\n        index-filter: int | list | tuple | set | None = None\n        mask-padding: int | str = 32\n        mask-blur: int = 4\n        mask-dilation: int = 4\n        model-masks: bool = False\n        confidence: float = 0.3\n        detector-device: Optional[str] = None\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    adetailer, diffusion based post processor for SD1.5, SDXL, Kolors, SD3, and Flux\n\n    adetailer can detect features of your image and automatically generate an inpaint mask for them,\n    such as faces, hands etc. and then re-run diffusion over those portions of the image using\n    inpainting to enhance detail.\n\n    This image processor may only be used if a diffusion pipeline has been previously executed by\n    dgenerate, that pipeline will be used to process the inpainting done by adetailer. For a single\n    command line invocation you must use --post-processors to use this image processor correctly. In\n    dgenerate config script, you may use it anywhere, and the last executed diffusion pipeline will\n    be reused for inpainting.\n\n    Inpainting will occur on the device used by the last executed diffusion pipeline unless the\n    \"device\" argument is specified, the detector model can be run on an alternate GPU if desired\n    using the \"detector-device\" argument, otherwise the detector will run on \"device\".\n\n    Example:\n\n    --post-processors \"adetailer;\\\n                       model=Bingsu/adetailer;\\\n                       weight-name=face_yolov8n.pt;\\\n                       prompt=detailed image of a mans face;\\\n                       negative-prompt=nsfw, blurry, disfigured;\\\n                       guidance-scale=7;\\\n                       inference-steps=30;\\\n                       strength=0.4\"\n\n    -----\n\n    The \"model\" argument specifies which YOLO model to use. This can be a path to a local model\n    file, a URL to download the model from, or a HuggingFace repository slug / blob link.\n\n    The \"prompt\" argument specifies the positive prompt to use for inpainting.\n\n    The \"negative-prompt\" argument specifies the negative prompt for inpainting.\n\n    The \"prompt-weighter\" argument specifies a prompt weighter plugin for applying prompt weighting\n    to the provided positive and negative prompts. Prompt weighters may have arguments, when\n    supplying URI arguments to a prompt weighter you must use double quoting around the prompt\n    weighter definition, i.e: --post-processors\n    \"adetailer;model=...;prompt=test;prompt-weighter='compel;syntax=sdwui'\"\n\n    The \"weight-name\" argument specifies the file name in a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument.\n\n    The \"subfolder\" argument specifies the subfolder in a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument.\n\n    The \"revision\" argument specifies the revision of a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument. For example:\n    \"main\"\n\n    The \"token\" argument specifies your HuggingFace authentication token explicitly if needed.\n\n    The \"local-files-only\" argument specifies that dgenerate should not attempt to download any\n    model files, and to only look for them locally in the cache or otherwise.\n\n    The \"seed\" argument can be used to specify a specific seed for diffusion when preforming\n    inpainting on the input image.\n\n    The \"inference-steps\" argument specifies the amount of inference steps when preforming\n    inpainting on the input image.\n\n    The \"guidance-scale\" argument specifies the guidance scale for inpainting.\n\n    The \"pag-scale\" argument indicates the perturbed attention guidance scale, this enables a PAG\n    inpaint pipeline if supported. If the previously used pipeline was a PAG pipeline, PAG is\n    automatically enabled for inpainting if supported and this value defaults to 3.0 if not\n    supplied. The adetailer processor supports PAG with --model-type torch and torch-sdxl.\n\n    The \"pag-adaptive-scale\" argument indicates the perturbed attention guidance adaptive scale,\n    this enables a PAG inpaint pipeline if supported. If the previously usee pipeline was a PAG\n    pipeline, PAG is automatically enabled for inpainting if supported and this value defaults to\n    0.0 if not supplied. The adetailer processor supports PAG with --model-type torch and\n    torch-sdxl.\n\n    The \"strength\" argument is analogous to --image-seed-strengths\n\n    The \"class-filter\" argument can be used to detect only specific classes. This should be a\n    comma-separated list of class IDs or class names, or a single value, for example:\n    \"0,2,person,car\". This filter is applied before \"index-filter\".\n\n    Example \"class-filter\" values:\n\n        # Only keep detection class ID 0\n        class-filter=0\n\n        # Only keep detection class \"hand\"\n        class-filter=hand\n\n        # keep class ID 2,3\n        class-filter=2,3\n\n        # keep class ID 0 & class Name \"hand\"\n        # if entry cannot be parsed as an integer\n        # it is interpreted as a name\n        class-filter=0,hand\n\n        # \"0\" is interpreted as a name and not an ID,\n        # this is not likely to be useful\n        class-filter=\"0\",hand\n\n        # List syntax is supported, you must quote\n        # class names\n        index-filter=[0, \"hand\"]\n\n    The \"index-filter\" argument is a list values or a single value that indicates what YOLO\n    detection indices to keep, the index values start at zero. Detections are sorted by their top\n    left bounding box coordinate from left to right, top to bottom, by (confidence descending). The\n    order of detections in the image is identical to the reading order of words on a page (english).\n    Inpainting will only be preformed on the specified detection indices, if no indices are\n    specified, then inpainting will be preformed on all detections.\n\n    Example \"index-filter\" values:\n\n        # keep the first, leftmost, topmost detection\n        index-filter=0\n\n        # keep detections 1 and 3\n        index-filter=[1, 3]\n\n        # CSV syntax is supported (tuple)\n        index-filter=1,3\n\n    The \"detector-padding\" argument specifies the amount of padding that will be added to the\n    detection rectangle which is used to generate a masked area. The default is 0, you can make the\n    mask area around the detected feature larger with positive padding and smaller with negative\n    padding.\n\n    Padding examples:\n\n        32 (32px Uniform, all sides)\n\n        10x20 (10px Horizontal, 20px Vertical)\n\n        10x20x30x40 (10px Left, 20px Top, 30px Right, 40px Bottom)\n\n    The \"mask-padding\" argument indicates how much padding to place around the masked area when\n    cropping out the image to be inpainted. This value must be large enough to accommodate any\n    feathering on the edge of the mask caused by \"mask-blur\" or \"mask-dilation\" for the best result,\n    the default value is 32. The syntax for specifying this value is identical to\n    \"detector-padding\".\n\n    The \"mask-shape\" argument indicates what mask shape adetailer should attempt to draw around a\n    detected feature, the default value is \"rectangle\". You may also specify \"circle\" to generate an\n    ellipsoid shaped mask, which might be helpful for achieving better blending.\n\n    The \"mask-blur\" argument indicates the level of gaussian blur to apply to the generated inpaint\n    mask, which can help with smooth blending in of the inpainted feature\n\n    The \"mask-dilation\" argument indicates the amount of dilation applied to the inpaint mask, see:\n    cv2.dilate\n\n    The \"model-masks\" argument indicates that masks generated by the model itself should be\n    preferred over masks generated from the detection bounding box. If this is True, and the model\n    itself returns mask data, \"mask-shape\", \"mask-padding\", and \"detector-padding\" will all be\n    ignored.\n\n    The \"confidence\" argument can be used to adjust the confidence value for the YOLO detector\n    model. Defaults to: 0.3\n\n    The \"detector-device\" argument can be used to specify a device override for the YOLO detector,\n    i.e. the GPU / Accelerate device the model will run on. Example: cuda:0, cuda:1, cpu\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "anyline": {"gaussian-sigma": {"optional": false, "types": ["float"], "default": 2.0}, "intensity-threshold": {"optional": false, "types": ["int"], "default": 2}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "anyline:\n    arguments:\n        gaussian-sigma: float = 2.0\n        intensity-threshold: int = 2\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    anyline, MistoLine Control Every Line image preprocessor, see:\n    https://huggingface.co/TheMistoAI/MistoLine\n\n    This is an edge detector based on TEED.\n\n    The \"gaussian-sigma\" argument is the gaussian filter sigma value.\n\n    The \"intensity-threshold\" argument is the pixel value intensity threshold.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "canny": {"lower": {"optional": false, "types": ["int"], "default": 50}, "upper": {"optional": false, "types": ["int"], "default": 100}, "aperture-size": {"optional": false, "types": ["int"], "default": 3}, "L2-gradient": {"optional": false, "types": ["bool"], "default": false}, "blur": {"optional": false, "types": ["bool"], "default": false}, "gray": {"optional": false, "types": ["bool"], "default": false}, "threshold-algo": {"optional": true, "types": ["str"], "default": null}, "sigma": {"optional": false, "types": ["float"], "default": 0.33}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "canny:\n    arguments:\n        lower: int = 50\n        upper: int = 100\n        aperture-size: int = 3\n        L2-gradient: bool = False\n        blur: bool = False\n        gray: bool = False\n        threshold-algo: str | None = None\n        sigma: float = 0.33\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Process the input image with the Canny edge detection algorithm.\n\n    The \"lower\" argument indicates the lower threshold value for the algorithm, and the \"upper\"\n    argument indicates the upper threshold. \"aperture-size\" is the size of Sobel kernel used for\n    find image gradients, it must be an odd integer from 3 to 7. \"L2-gradient\" specifies the\n    equation for finding gradient magnitude, if True a more accurate equation is used. See:\n    https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html.\n\n    If \"blur\" is true, apply a 3x3 gaussian blur before processing. If \"gray\" is true, convert the\n    image to the cv2 \"GRAY\" format before processing, which does not happen automatically unless you\n    are using a \"threshold_algo\" value, OpenCV is capable of edge detection on colored images,\n    however you may find better results by converting to its internal grayscale format before\n    processing, or you may not, it depends.\n\n    If \"threshold_algo\" is one of (\"otsu\", \"triangle\", \"median\") try to calculate the lower and\n    upper threshold automatically using cv2.threshold or cv2.median in the case of \"median\". \"sigma\"\n    scales the range of the automatic threshold calculation done when a value for \"threshold_algo\"\n    is selected. \"pre-resize\" is a boolean value determining if the processing should take place\n    before or after the image is resized by dgenerate.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "crop": {"box": {"optional": false, "types": ["str"]}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "crop:\n    arguments:\n        box: str\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Crop the input image to a specified box region.\n\n    The \"box\" argument specifies the crop region in the format \"LEFTxTOPxRIGHTxBOTTOM\", where each\n    value represents pixel coordinates. For example: \"100x50x300x400\" will crop the image with top\n    left: (x=100, y=50), bottom right: (x=300, y=400)\n\n    The \"pre-resize\" argument determines if the cropping occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is cropped after dgenerate is done resizing\n    it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "dilate": {"size": {"types": ["int", "str"], "default": 3}, "steps": {"optional": false, "types": ["int"], "default": 1}, "shape": {"optional": false, "types": ["str"], "default": "rectangle"}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "dilate:\n    arguments:\n        size: int | str = 3\n        steps: int = 1\n        shape: str = \"rectangle\"\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Apply morphological dilation to the input image using OpenCV.\n\n    Dilation is a morphological operation that expands white regions (foreground objects) in a\n    binary or grayscale image. It's commonly used to fill small holes inside objects or to connect\n    nearby objects.\n\n    The \"size\" argument specifies the size of the structuring element used for dilation. It can be\n    either an odd integer (e.g., 3, 5, 7, etc.) representing both width and height, or a string\n    specifying different dimensions like \"5x3\" for width x height. All dimensions must be odd\n    positive integers.\n\n    The \"steps\" argument specifies how many times the dilation operation is applied. More steps\n    result in more expansion.\n\n    The \"shape\" argument specifies the shape of the structuring element:\n\n    - \"r\" or \"rect\" or \"rectangle\": rectangular kernel (default)\n    - \"c\" or \"circle\" or \"ellipse\": elliptical kernel\n    - \"+\" or \"cross\": cross-shaped kernel\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "flip": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "flip:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Flip the input image vertically.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "gaussian-blur": {"size": {"types": ["int", "str"], "default": 5}, "sigma-x": {"optional": false, "types": ["float"], "default": 0.0}, "sigma-y": {"optional": false, "types": ["float"], "default": 0.0}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "gaussian-blur:\n    arguments:\n        size: int | str = 5\n        sigma-x: float = 0.0\n        sigma-y: float = 0.0\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Apply Gaussian blur to the input image using OpenCV.\n\n    Gaussian blur is a widely used effect in image processing that reduces image noise and detail by\n    convolving the image with a Gaussian kernel.\n\n    The \"size\" argument specifies the size of the Gaussian kernel. It can be either an odd integer\n    (e.g., 3, 5, 7, etc.) representing both width and height, or a string specifying different\n    dimensions like \"5x3\" for width x height. All dimensions must be odd positive integers. Larger\n    kernel sizes produce more blur.\n\n    The \"sigma-x\" argument specifies the standard deviation in the X direction. If 0, it's\n    calculated from the kernel size.\n\n    The \"sigma-y\" argument specifies the standard deviation in the Y direction. If 0, it's set to\n    the same value as sigma-x.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "grayscale": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "grayscale:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Convert the input image to grayscale.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "hed": {"scribble": {"optional": false, "types": ["bool"], "default": false}, "safe": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "hed:\n    arguments:\n        scribble: bool = False\n        safe: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    HED detection (holistically-nested edge detection), this is an edge detection algorithm that can\n    produced something akin to thick lineart.\n\n    The \"scribble\" argument determines whether scribble mode is enabled, this produces thicker\n    lines.\n\n    The \"safe\" argument enables or disables numerically safe / more precise stepping.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect_resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "invert": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "invert:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Invert the colors of the input image.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "leres": {"threshold-near": {"optional": false, "types": ["int"], "default": 0}, "threshold-far": {"optional": false, "types": ["int"], "default": 0}, "boost": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "leres:\n    arguments:\n        threshold-near: int = 0\n        threshold-far: int = 0\n        boost: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    LeReS depth detector.\n\n    The \"threshold-near\" argument is the near threshold, think the low threshold of canny.\n\n    The \"threshold-far\" argument is the far threshold, think the high threshold of canny.\n\n    The \"boost\" argument determines if monocular depth boost is used.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "letterbox": {"box-size": {"optional": false, "types": ["str"]}, "box-is-padding": {"optional": false, "types": ["bool"], "default": false}, "box-color": {"optional": true, "types": ["str"], "default": null}, "inner-size": {"optional": true, "types": ["str"], "default": null}, "aspect-correct": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "letterbox:\n    arguments:\n        box-size: str\n        box-is-padding: bool = False\n        box-color: str | None = None\n        inner-size: str | None = None\n        aspect-correct: bool = True\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Letterbox an image.\n\n    The \"box-size\" argument is the size of the outer letterbox.\n\n    The \"box-is-padding\" argument can be used to indicate that \"box-size\" should be interpreted as\n    padding.\n\n    The \"box-color\" argument specifies the color to use for the letter box background, the default\n    is black. This should be specified as a HEX color code. e.g. #FFFFFF or #FFF\n\n    The \"inner-size\" argument specifies the size of the inner image.\n\n    The \"aspect-correct\" argument can be used to determine if the aspect ratio of the inner image is\n    maintained or not.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "lineart": {"course": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "lineart:\n    arguments:\n        course: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Line art generator, generate line art from an image.\n\n    The \"course\" argument determines whether to use the course model or the normal model.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "lineart-anime": {"detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "lineart-anime:\n    arguments:\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Anime line art generator, generate anime line art from an image.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "lineart-standard": {"gaussian-sigma": {"optional": false, "types": ["float"], "default": 6.0}, "intensity-threshold": {"optional": false, "types": ["int"], "default": 8}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "lineart-standard:\n    arguments:\n        gaussian-sigma: float = 6.0\n        intensity-threshold: int = 8\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Standard lineart detector, generate lineart from an image.\n\n    The \"gaussian-sigma\" argument is the gaussian filter sigma value.\n\n    The \"intensity-threshold\" argument is the pixel value intensity threshold.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "midas": {"normals": {"optional": false, "types": ["bool"], "default": false}, "alpha": {"optional": false, "types": ["float"], "default": 6.283185307179586}, "background-threshold": {"optional": false, "types": ["float"], "default": 0.1}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "midas:\n    arguments:\n        normals: bool = False\n        alpha: float = 6.283185307179586\n        background-threshold: float = 0.1\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    MiDaS depth detector and normal map generation.\n\n    The \"normals\" argument determines if this processor produces a normal map or a depth image.\n\n    The \"alpha\" argument is related to normal map generation.\n\n    The \"background_threshold\" argument is related to normal map generation.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "mirror": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "mirror:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Mirror the input image horizontally.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "mlsd": {"threshold-score": {"optional": false, "types": ["float"], "default": 0.1}, "threshold-distance": {"optional": false, "types": ["float"], "default": 0.1}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "mlsd:\n    arguments:\n        threshold-score: float = 0.1\n        threshold-distance: float = 0.1\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Machine Learning Model for Detecting Wireframes. Wireframe edge detector, this processor\n    overlays lines on to the edges of objects in an image.\n\n    The \"threshold-score\" argument is the score threshold.\n\n    The \"threshold-distance\" argument is the distance threshold.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "normal-bae": {"detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "normal-bae:\n    arguments:\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Normal Bae Detector, generate a normal map from an image.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "openpose": {"include-body": {"optional": false, "types": ["bool"], "default": true}, "include-hand": {"optional": false, "types": ["bool"], "default": false}, "include-face": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "openpose:\n    arguments:\n        include-body: bool = True\n        include-hand: bool = False\n        include-face: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Generate an OpenPose rigging from the input image (of a human/humanoid) for use with a\n    ControlNet.\n\n    \"include-body\" is a boolean value indicating if a body rigging should be generated.\n\n    \"include-hand\" is a boolean value indicating if a detailed hand/finger rigging should be\n    generated.\n\n    \"include-face\" is a boolean value indicating if a detailed face rigging should be generated.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "paste": {"image": {"optional": false, "types": ["str"]}, "position": {"optional": false, "types": ["str"], "default": "0x0"}, "feather": {"optional": true, "types": ["int"], "default": null}, "feather-shape": {"optional": false, "types": ["str"], "default": "rectangle"}, "mask": {"optional": true, "types": ["str"], "default": null}, "reverse": {"optional": false, "types": ["bool"], "default": false}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "paste:\n    arguments:\n        image: str\n        position: str = \"0x0\"\n        feather: int | None = None\n        feather-shape: str = \"rectangle\"\n        mask: str | None = None\n        reverse: bool = False\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Paste an image on top of the incoming image at a specified position.\n\n    The \"image\" argument specifies the path to the image file to paste.\n\n    The \"position\" argument specifies where to paste the image. It can be:\n\n    - \"LEFTxTOP\" format (e.g., \"100x50\") to specify the top-left coordinate\n    - \"LEFTxTOPxRIGHTxBOTTOM\" format (e.g., \"100x50x300x200\") to specify a bounding\n      box where the source image will be resized to fit\n\n    The \"feather\" argument specifies the feathering radius in pixels for softening edges. This\n    creates smooth transitions from opaque to transparent. If not specified, no feathering is\n    applied. Cannot be used together with the \"mask\" parameter.\n\n    The \"feather-shape\" argument controls the shape of the feathering:\n\n    - \"r\" or \"rect\" or \"rectangle\" (default): Rectangular feathering from edges\n    - \"c\" or \"circle\" or \"ellipse\": Elliptical feathering from center\n\n    Only used when \"feather\" is specified.\n\n    The \"mask\" argument allows you to specify a mask image path that will be used to control the\n    transparency of the pasted image. The mask should be a grayscale image where white areas\n    represent full opacity and black areas represent full transparency. Cannot be used together with\n    the \"feather\" parameter.\n\n    The \"reverse\" argument allows you to reverse the paste operation, meaning the \"image\" argument\n    is to be considered the background, and the processed image is to be the pasted content.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "patchmatch": {"mask": {"optional": false, "types": ["str"]}, "invert": {"optional": false, "types": ["bool"], "default": false}, "patch-size": {"optional": false, "types": ["int"], "default": 5}, "seed": {"optional": true, "types": ["int"], "default": null}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "patchmatch:\n    arguments:\n        mask: str\n        invert: bool = False\n        patch-size: int = 5\n        seed: int | None = None\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Inpaint an image with the PatchMatch algorithm (content aware fill).\n\n    The PatchMatch algorithm is used in this processor for pyramidical inpainting (filling in\n    missing or masked areas) in images. This processor requires a mask image to be provided via the\n    \"mask\" argument.  The mask should be a grayscale image where white pixels (255) indicate areas\n    to inpaint and black pixels (0) indicate areas to preserve.\n\n    The \"mask\" argument should point to a file path on disk or a URL that can be downloaded. Both\n    local files and remote URLs are supported. The mask will be resized to the dimension of the\n    incoming image if they are not the same size.\n\n    The \"invert\" argument allows you to treat the incoming mask image as if it has been inverted.\n\n    The \"patch-size\" argument specifies the patch size for the PatchMatch algorithm. Larger patch\n    sizes can provide better coherence but may be slower.\n\n    The \"seed\" argument allows you to specify a random number generator seed for reproducible\n    results.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "pidi": {"apply-filter": {"optional": false, "types": ["bool"], "default": false}, "safe": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "pidi:\n    arguments:\n        apply-filter: bool = False\n        safe: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    PidiNet (Pixel Difference Networks for Efficient Edge Detection) edge detector.\n\n    The \"apply-filter\" argument enables possibly crisper edges / less noise.\n\n    The \"safe\" argument enables or disables numerically safe / more precise stepping.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "posterize": {"bits": {"optional": false, "types": ["int"]}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "posterize:\n    arguments:\n        bits: int\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Posterize the input image with PIL.ImageOps.posterize.\n\n    Accepts the argument 'bits', an integer value from 1 to 8.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "resize": {"size": {"optional": true, "types": ["str"], "default": null}, "scale": {"optional": true, "types": ["float", "tuple"], "default": null}, "align": {"optional": true, "types": ["int"], "default": null}, "aspect-correct": {"optional": false, "types": ["bool"], "default": true}, "algo": {"optional": false, "types": ["str"], "default": "auto"}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "resize:\n    arguments:\n        size: str | None = None\n        scale: float | tuple[float, float] | None = None\n        align: int | None = None\n        aspect-correct: bool = True\n        algo: str = \"auto\"\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Resize an image using basic resampling algorithms.\n\n    The \"size\" argument is the new image size.\n\n    The \"scale\" argument is either a single floating point value to scale both dimensions by, or a\n    tuple of two floating point values to scale x and y dimensions separately. This is mutually\n    exclusive with \"size\". When specifying a tuple, you may use CSV, for example: \"2,1\", meaning\n    X*2, Y*1.\n\n    The \"align\" argument is the new image alignment.\n\n    The \"aspect-correct\" argument is a boolean argument that determines if the resize is aspect\n    correct.\n\n    The \"algo\" argument is the resize filtering algorithm, which can be one of: \"auto\", \"nearest\",\n    \"box\", \"bilinear\", \"hamming\", \"bicubic\", \"lanczos\"\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "sam": {"detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "sam:\n    arguments:\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Segment Anything Model, this processor attempts to create cutouts for every distinct object in\n    an image.\n\n    Note that this processor is just for use with controlnet models that support SAM annotated input\n    images.\n\n    If you want to generate masks or preview segmentation using prompting, use the \"u-sam\" processor\n    instead.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "solarize": {"threshold": {"optional": false, "types": ["int"], "default": 128}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "solarize:\n    arguments:\n        threshold: int = 128\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Solarize the input image with PIL.ImageOps.solarize.\n\n    Accepts the argument \"threshold\" which is an integer value from 0 to 255.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "teed": {"safe": {"optional": false, "types": ["bool"], "default": true}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "teed:\n    arguments:\n        safe: bool = True\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    teed, a (tiny efficient edge detector).\n\n    The \"safe\" argument enables or disables numerically safe / more precise stepping.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "u-sam": {"asset": {"optional": false, "types": ["str"]}, "points": {"optional": true, "types": ["list", "str", "tuple"], "default": null}, "boxes": {"optional": true, "types": ["list", "str", "tuple"], "default": null}, "font-size": {"optional": true, "types": ["int"], "default": null}, "line-width": {"optional": true, "types": ["int"], "default": null}, "line-color": {"optional": true, "types": ["str"], "default": null}, "masks": {"optional": false, "types": ["bool"], "default": false}, "outpaint": {"optional": false, "types": ["bool"], "default": false}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "u-sam:\n    arguments:\n        asset: str\n        points: str | list | tuple | None = None\n        boxes: str | list | tuple | None = None\n        font-size: int | None = None\n        line-width: int | None = None\n        line-color: str | None = None\n        masks: bool = False\n        outpaint: bool = False\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Process the input image with Ultralytics SAM (Segment Anything Model) using point or bounding\n    box prompts.\n\n    This processor operates in two distinct modes:\n\n    Preview Mode (default, masks=False):\n\n    Returns the original image with generated masks outlined and labeled with prompt indices. The\n    colors of the outlines and text are automatically chosen to contrast with the background for\n    optimal visibility.\n\n    Mask Mode (masks=True):\n\n    Returns a single composite mask image containing all generated masks combined together. This is\n    useful for inpainting, outpainting, or other mask-based image processing operations.\n\n    -----\n\n    The \"asset\" argument specifies which SAM model asset to use. This should be the name of an\n    Ultralytics SAM model asset, loading arbitrary checkpoints is not supported. This argument may\n    be one of:\n\n        * sam_h.pt\n        * sam_l.pt\n        * sam_b.pt\n        * mobile_sam.pt\n        * sam2_t.pt\n        * sam2_s.pt\n        * sam2_b.pt\n        * sam2_l.pt\n        * sam2.1_t.pt\n        * sam2.1_s.pt\n        * sam2.1_b.pt\n        * sam2.1_l.pt\n\n    You may exclude the `.pt` suffix if desired.\n\n    The \"local-files-only\" argument specifies that dgenerate should not attempt to download any\n    model files, and to only look for them locally in the cache or otherwise.\n\n    The \"points\" argument specifies point prompts as a list of coordinates. Each point can be\n    specified as either:\n\n    - Single point: [x, y] or x,y or \"x,y\"\n    - Nested list/tuple: [[x, y], ...] or [[x, y, label], ...] where label is 1 for foreground, 0 for background\n    - String format: [\"x,y\", ...] or [\"x,y,label\", ...]\n\n    Note that for string format, comma is interchangeable and mixable with the character \"x\".\n\n    If no label is provided, it defaults to 1 (foreground).\n\n    Examples:\n        points=[100,100]                    # Single point\n        points=100,100                      # Single point\n        points=100x100                      # Single point\n        points=[[100, 100], [200, 200, 0]]  # Nested format\n        points=[\"100,100\", \"200,200,0\"]     # String format\n        points=\"100,100\",\"200,200,0\"        # String format\n        points=[\"100x100\", \"200x200x0\"]     # String format\n        points=\"100x100\",\"200x200x0\"        # String format\n\n    The \"boxes\" argument specifies bounding box prompts as a list of coordinates. Each box can be\n    specified as either:\n\n    - Single box: [x1, y1, x2, y2] or x1,y1,x2,y2 or \"x1,y1,x2,y2\"\n    - Nested list/tuple: [[x1, y1, x2, y2], ...]\n    - String format: [\"x1,y1,x2,y2\", ...]\n\n    Examples:\n        boxes=[50, 50, 150, 150]                          # Single box\n        boxes=50,50,150,150                               # Single box\n        boxes=50x50x150x150                               # Single box\n        boxes=[[50, 50, 150, 150], [200, 200, 300, 300]]  # Nested format\n        boxes=[\"50,50,150,150\", \"200,200,300,300\"]        # String format\n        boxes=\"50,50,150,150\",\"200,200,300,300\"           # String format\n        boxes=\"50x50x150x150\",\"200x200x300x300\"           # String format\n\n    Note: You may use python tuple syntax as well as list syntax, additionally something such as:\n    (100,100),(100,100) will be interpreted as a tuple of of tuples, and: [100,100],[100,100] a\n    tuple of lists.\n\n    The \"font-size\" argument determines the size of the label text. If not specified, it will be\n    automatically calculated based on the image dimensions.\n\n    The \"line-width\" argument controls the thickness of the mask outline lines. If not specified, it\n    will be automatically calculated based on the image dimensions.\n\n    The \"line-color\" argument overrides the color for mask outlines and text label backgrounds. This\n    should be specified as a HEX color code, e.g. \"#FFFFFF\" or \"#FFF\". If not specified, colors are\n    automatically chosen to contrast with the background. The text color will always be\n    automatically chosen to contrast with the background for optimal readability.\n\n    The \"masks\" argument enables mask generation mode. When True, the processor returns a composite\n    mask image instead of the annotated preview image. This defaults to False.\n\n    The \"outpaint\" argument inverts the generated masks, creating inverted masks suitable for\n    outpainting operations. This only has an effect when \"masks\" is True. This defaults to False.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "upscaler": {"model": {"optional": false, "types": ["str"]}, "tile": {"types": ["int", "str"], "default": 512}, "overlap": {"optional": false, "types": ["int"], "default": 32}, "scale": {"optional": true, "types": ["int"], "default": null}, "force-tiling": {"optional": false, "types": ["bool"], "default": false}, "dtype": {"optional": false, "types": ["str"], "default": "float32"}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "upscaler:\n    arguments:\n        model: str\n        tile: int | str = 512\n        overlap: int = 32\n        scale: int | None = None\n        force-tiling: bool = False\n        dtype: str = \"float32\"\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Implements tiled upscaling with chaiNNer compatible upscaler models.\n\n    The \"model\" argument should be a path to a chaiNNer compatible upscaler model on disk, such as a\n    model downloaded from https://openmodeldb.info/, or an HTTP/HTTPS URL that points to a raw model\n    file. This may also be a Hugging Face blob link.\n\n    For example:\n    \"upscaler;model=https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth\"\n\n    Downloaded models are cached in the dgenerate web cache on disk until the cache expiry time for\n    the file is met.\n\n    The \"tile\" argument can be used to specify the tile size for tiled upscaling, it must be\n    divisible by 2, and defaults to 512. Specifying 'auto' indicates that this value should be\n    calculated based off available GPU memory if applicable. Specifying 0 disables tiling entirely.\n\n    The \"overlap\" argument can be used to specify the overlap amount of each tile in pixels, it must\n    be greater than or equal to 0, and defaults to 32.\n\n    The \"scale\" argument can be used to specify the output scale of the image regardless of the\n    models scale, this equates to an image resize on each tile output of the model as necessary,\n    with auto selected resizing algorithm for the best quality. This is effectively equivalent to\n    basic image resizing of the upscaled output post upscale, just with somewhat reduced memory\n    overhead as it occurs during tiling. When this argument is not specified, the scale of the model\n    architecture is used and no resizing occurs. This argument must be greater than or equal to 1.\n\n    The \"force-tiling\" argument can be used to force external image tiling for upscaler model\n    architectures which discourage the use of external tiling (SCUNEt and MixDehazeNet currently),\n    this may mean that the model needs information about the whole image to achieve a good result.\n    External tiling breaks up the image into tiles before feeding it to the model and reassembles\n    the images output by the model, this is not the default behavior when a model specifies that\n    tiling is discouraged, tiling is only on by default for models where external tiling is fully\n    supported. Only use this if you run into memory issues with models that discourage external\n    tiling, in the case that the model discourages its use, using it may result in substandard image\n    output.\n\n    The \"dtype\" argument can be used to specify the datatype to use to for the model in memory, it\n    can be either \"float32\" or \"float16\". Using \"float16\" will result in a smaller memory footprint\n    if supported.\n\n    The \"pre-resize\" argument is a boolean value determining if the processing should take place\n    before or after the image is resized by dgenerate.\n\n    Example: \"upscaler;model=my-model.pth;tile=256;overlap=16\"\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "upscaler-ncnn": {"model": {"optional": false, "types": ["str"]}, "param": {"optional": false, "types": ["str"]}, "use-gpu": {"optional": false, "types": ["bool"], "default": false}, "gpu-index": {"optional": false, "types": ["int"], "default": 0}, "threads": {"types": ["int", "str"], "default": "auto"}, "blocktime": {"optional": true, "types": ["int"], "default": null}, "winograd": {"optional": true, "types": ["bool"], "default": null}, "sgemm": {"optional": true, "types": ["bool"], "default": null}, "tile": {"optional": false, "types": ["int"], "default": 400}, "overlap": {"optional": false, "types": ["int"], "default": 8}, "scale": {"optional": true, "types": ["int"], "default": null}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "upscaler-ncnn:\n    arguments:\n        model: str\n        param: str\n        use-gpu: bool = False\n        gpu-index: int = 0\n        threads: int | str = \"auto\"\n        blocktime: int | None = None\n        winograd: bool | None = None\n        sgemm: bool | None = None\n        tile: int = 400\n        overlap: int = 8\n        scale: int | None = None\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Implements tiled upscaling with NCNN upscaler models.\n\n    The \"model\" argument should be a path or URL to a NCNN compatible upscaler model. This may also\n    be a Hugging Face blob link.\n\n    The \"param\" argument should be a path or URL to the NCNN param file for the model. This may also\n    be a Hugging Face blob link.\n\n    Downloaded model / param files are cached in the dgenerate web cache on disk until the cache\n    expiry time for the file is met.\n\n    When using this processor as a pre-processor or post-processor for diffusion, GPU memory will be\n    fenced, any cached models related to diffusion on the GPU will be evacuated entirely before this\n    processor runs if they exist on the same GPU as the processor, this is to prevent catastrophic\n    interaction between the Vulkan and Torch cuda allocators.\n\n    Once a Vulkan allocator exists on a specific GPU it cannot be destroyed except via the process\n    exiting due to issues with the ncnn python binding. If you create this processor on a GPU you\n    intend to perform diffusion on, you are going to run into memory errors after the first image\n    generation and there on out until the process exits.\n\n    When the process exits it is very likely to exit with a non-zero return code after using this\n    processor even if the upscale operations were successful, this is due to problems with the ncnn\n    python binding creating a segfault at exit. If you are using dgenerate interactively in shell\n    mode or from the Console UI, this will occur without consequence when the interpreter process\n    exits.\n\n    Note that if any other process runs diffusion / inference via torch on the same GPU as this\n    image processor while ncnn is preforming inference, you will likely encounter a segfault in\n    either of the processes and a very hard crash.\n\n    You can safely run this processor in parallel with diffusion, or other torch based image\n    processors with GPU acceleration, by placing it on a separate gpu using the \"gpu-index\"\n    argument.\n\n    For these reasons, this processor runs on the CPU by default, you can enable GPU usage with GPU\n    related arguments mentioned in this documentation below.\n\n    -----\n\n    The \"use-gpu\" argument determines if the gpu is used, defaults to False.\n\n    The \"gpu-index\" argument determines which gpu is used, it is 0 indexed, and defaults to 0 which\n    is most likely your main GPU.\n\n    The \"threads\" argument determines the number of cpu threads used, the default value is \"auto\"\n    which uses the maximum amount. You may also pass \"half\" to use half the cpus logical thread\n    count.\n\n    The \"blocktime\" argument determines the blocktime in milliseconds for OpenMP parallelization\n    when running on the cpu, this value should be between 0 and 400 milliseconds, if you do not\n    specify the NCNN default for your platform is used. You cannot use this argument when running on\n    the GPU, an argument error will be thrown.\n\n    The \"winograd\" argument determines if the winograd convolution optimization is used when running\n    on the CPU. If you do not specify it, the NCNN default for you platform is used. You cannot use\n    this argument when running on the GPU, an argument error will be thrown.\n\n    The \"sgemm\" argument determines if the sgemm convolution optimization is used when running on\n    the CPU. If you do not specify it, the NCNN default for you platform is used. You cannot use\n    this argument when running on the GPU, an argument error will be thrown.\n\n    The \"tile\" argument can be used to specify the tile size for tiled upscaling, it must be\n    divisible by 2 and be less than or equal to 400, the default is 400. Tile size is limited to a\n    max of 400 due to memory allocator issues in ncnn. You may disable tiling by setting \"tile=0\"\n    however, you can only do this for images under 400 pixels in both dimensions, if the image is\n    over 400 pixels in any dimension, and you disabled tiling, a usage error will be thrown.\n\n    The \"overlap\" argument can be used to specify the overlap amount of each tile in pixels, it must\n    be greater than or equal to 0, and defaults to 8.\n\n    The \"scale\" argument can be used to specify the output scale of the image regardless of the\n    models scale, this equates to an image resize on each tile output of the model as necessary,\n    with auto selected resizing algorithm for the best quality. This is effectively equivalent to\n    basic image resizing of the upscaled output post upscale, just with somewhat reduced memory\n    overhead as it occurs during tiling. When this argument is not specified, the scale of the model\n    architecture is used and no resizing occurs. This argument must be greater than or equal to 1.\n\n    The \"pre-resize\" argument is a boolean value determining if the processing should take place\n    before or after the image is resized by dgenerate.\n\n    x4.bin: https://github.com/nihui/realsr-ncnn-vulkan/blob/master/models/models-DF2K/x4.bin\n    x4.param: https://github.com/nihui/realsr-ncnn-vulkan/blob/master/models/models-DF2K/x4.param\n\n    Example: \"upscaler-ncnn;model=x4.bin;param=x4.param;tile=256;overlap=16;use-gpu=True\"\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "yolo": {"model": {"optional": false, "types": ["str"]}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "revision": {"optional": true, "types": ["str"], "default": null}, "token": {"optional": true, "types": ["str"], "default": null}, "font-size": {"optional": true, "types": ["int"], "default": null}, "line-width": {"optional": true, "types": ["int"], "default": null}, "line-color": {"optional": true, "types": ["str"], "default": null}, "class-filter": {"optional": true, "types": ["int", "list", "set", "str", "tuple"], "default": null}, "index-filter": {"optional": true, "types": ["int", "list", "set", "tuple"], "default": null}, "confidence": {"optional": false, "types": ["float"], "default": 0.3}, "model-masks": {"optional": false, "types": ["bool"], "default": false}, "masks": {"optional": false, "types": ["bool"], "default": false}, "outpaint": {"optional": false, "types": ["bool"], "default": false}, "detector-padding": {"types": ["int", "str"], "default": 0}, "mask-shape": {"optional": false, "types": ["str"], "default": "rectangle"}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "yolo:\n    arguments:\n        model: str\n        weight-name: str | None = None\n        subfolder: str | None = None\n        revision: str | None = None\n        token: str | None = None\n        font-size: int | None = None\n        line-width: int | None = None\n        line-color: str | None = None\n        class-filter: int | str | list | tuple | set | None = None\n        index-filter: int | list | tuple | set | None = None\n        confidence: float = 0.3\n        model-masks: bool = False\n        masks: bool = False\n        outpaint: bool = False\n        detector-padding: int | str = 0\n        mask-shape: str = \"rectangle\"\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Process the input image with Ultralytics YOLO object detection.\n\n    This processor operates in two distinct modes:\n\n    Detection Mode (default, masks=False):\n\n    Returns the original image with bounding boxes or mask outlines drawn around detected objects,\n    along with labels showing the detection index, class ID, and class name. The colors of the boxes\n    and text are automatically chosen to contrast with the background for optimal visibility.\n\n    Mask Mode (masks=True):\n\n    Returns a single composite mask image containing all detected objects combined together. This is\n    useful for inpainting, outpainting, or other mask-based image processing operations.\n\n    -----\n\n    The \"model\" argument specifies which YOLO model to use. This can be a path to a local model\n    file, a URL to download the model from, or a HuggingFace repository slug / blob link.\n\n    The \"weight-name\" argument specifies the file name in a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument.\n\n    The \"subfolder\" argument specifies the subfolder in a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument.\n\n    The \"revision\" argument specifies the revision of a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument. For example:\n    \"main\"\n\n    The \"token\" argument specifies your HuggingFace authentication token explicitly if needed for\n    accessing private repositories.\n\n    The \"local-files-only\" argument specifies that dgenerate should not attempt to download any\n    model files, and to only look for them locally in the cache or otherwise.\n\n    The \"font-size\" argument determines the size of the label text. If not specified, it will be\n    automatically calculated based on the image dimensions.\n\n    The \"line-width\" argument controls the thickness of the bounding box lines. If not specified, it\n    will be automatically calculated based on the image dimensions.\n\n    The \"line-color\" argument overrides the color for bounding box lines, mask outlines, and text\n    label backgrounds. This should be specified as a HEX color code, e.g. \"#FFFFFF\" or \"#FFF\". If\n    not specified, colors are automatically chosen to contrast with the background. The text color\n    will always be automatically chosen to contrast with the background for optimal readability.\n\n    The \"class-filter\" argument can be used to detect only specific classes. This should be a\n    comma-separated list of class IDs or class names, or a single value, for example:\n    \"0,2,person,car\". This filter is applied before \"index-filter\".\n\n    Example \"class-filter\" values:\n\n        # Only keep detection class ID 0\n        class-filter=0\n\n        # Only keep detection class \"hand\"\n        class-filter=hand\n\n        # keep class ID 2,3\n        class-filter=2,3\n\n        # keep class ID 0 & class Name \"hand\"\n        # if entry cannot be parsed as an integer\n        # it is interpreted as a name\n        class-filter=0,hand\n\n        # \"0\" is interpreted as a name and not an ID,\n        # this is not likely to be useful\n        class-filter=\"0\",hand\n\n        # List syntax is supported, you must quote\n        # class names\n        class-filter=[0, \"hand\"]\n\n    The \"index-filter\" argument is a list values or a single value that indicates what YOLO\n    detection indices to keep, the index values start at zero. Detections are sorted by their top\n    left bounding box coordinate from left to right, top to bottom, by (confidence descending). The\n    order of detections in the image is identical to the reading order of words on a page (english).\n    Processing will only be performed on the specified detection indices, if no indices are\n    specified, then processing will be performed on all detections.\n\n    Example \"index-filter\" values:\n\n        # keep the first, leftmost, topmost detection\n        index-filter=0\n\n        # keep detections 1 and 3\n        index-filter=[1, 3]\n\n        # CSV syntax is supported (tuple)\n        index-filter=1,3\n\n    The \"confidence\" argument sets the confidence threshold for detections (0.0 to 1.0), defaults\n    to: 0.3\n\n    The \"model-masks\" argument indicates that masks generated by the model itself should be overlaid\n    on the image instead of just bounding boxes. If this is True, and the model returns mask data,\n    mask outlines will be drawn instead of bounding boxes. This defaults to False.\n\n    The \"masks\" argument enables mask generation mode. When True, the processor returns a composite\n    mask image instead of the annotated detection image. This defaults to False.\n\n    The \"outpaint\" argument inverts the generated masks, creating inverted masks suitable for\n    outpainting operations. This only has an effect when \"masks\" is True. This defaults to False.\n\n    The \"detector-padding\" argument specifies the amount of padding that will be added to the\n    detection rectangle for both bounding box drawing and mask generation. The default is 0, you can\n    make the bounding box and mask area around the detected feature larger with positive padding and\n    smaller with negative padding.\n\n    Padding examples:\n\n        32 (32px Uniform, all sides)\n\n        10x20 (10px Horizontal, 20px Vertical)\n\n        10x20x30x40 (10px Left, 20px Top, 30px Right, 40px Bottom)\n\n    The \"mask-shape\" argument indicates what mask shape should be drawn around a detected feature,\n    the default value is \"rectangle\". You may also specify \"circle\" to generate an ellipsoid shaped\n    mask.\n\n    Note: When \"model-masks\" is True and the model returns mask data, the \"detector-padding\" and\n    \"mask-shape\" arguments will be ignored as the model's own masks are used directly.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "zoe": {"gamma-corrected": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "zoe:\n    arguments:\n        gamma-corrected: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    zoe depth detector, a SOTA depth estimation model which produces high-quality depth maps.\n\n    The \"gamma-corrected\" argument determines if gamma correction is preformed on the produced depth\n    math.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}}