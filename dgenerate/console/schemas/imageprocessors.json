{"adetailer": {"model": {"optional": false, "types": ["str"]}, "prompt": {"optional": false, "types": ["str"]}, "negative-prompt": {"optional": true, "types": ["str"], "default": null}, "prompt-weighter": {"optional": true, "types": ["str"], "default": null}, "weight-name": {"optional": true, "types": ["str"], "default": null}, "subfolder": {"optional": true, "types": ["str"], "default": null}, "revision": {"optional": true, "types": ["str"], "default": null}, "token": {"optional": true, "types": ["str"], "default": null}, "seed": {"optional": true, "types": ["int"], "default": null}, "inference-steps": {"optional": false, "types": ["int"], "default": 30}, "guidance-scale": {"optional": false, "types": ["float"], "default": 5}, "pag-scale": {"optional": true, "types": ["float"], "default": null}, "pag-adaptive-scale": {"optional": true, "types": ["float"], "default": null}, "strength": {"optional": false, "types": ["float"], "default": 0.4}, "detector-padding": {"optional": false, "types": ["str"], "default": "0"}, "mask-shape": {"optional": false, "types": ["str"], "default": "rectangle"}, "index-filter": {"optional": true, "types": ["int", "list", "tuple"], "default": null}, "mask-padding": {"optional": false, "types": ["str"], "default": "32"}, "mask-blur": {"optional": false, "types": ["int"], "default": 4}, "mask-dilation": {"optional": false, "types": ["int"], "default": 4}, "confidence": {"optional": false, "types": ["float"], "default": 0.3}, "detector-device": {"optional": true, "types": ["str"], "default": null}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "adetailer:\n    arguments:\n        model: str\n        prompt: str\n        negative-prompt: str | None = None\n        prompt-weighter: str | None = None\n        weight-name: str | None = None\n        subfolder: str | None = None\n        revision: str | None = None\n        token: str | None = None\n        seed: int | None = None\n        inference-steps: int = 30\n        guidance-scale: float = 5\n        pag-scale: float | None = None\n        pag-adaptive-scale: float | None = None\n        strength: float = 0.4\n        detector-padding: str = \"0\"\n        mask-shape: str = \"rectangle\"\n        index-filter: int | list | tuple | None = None\n        mask-padding: str = \"32\"\n        mask-blur: int = 4\n        mask-dilation: int = 4\n        confidence: float = 0.3\n        detector-device: Optional[str] = None\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    adetailer, diffusion based post processor for SD1.5, SDXL, Kolors, SD3, and Flux\n\n    adetailer can detect features of your image and automatically generate an inpaint mask for them,\n    such as faces, hands etc. and then re-run diffusion over those portions of the image using\n    inpainting to enhance detail.\n\n    This image processor may only be used if a diffusion pipeline has been previously executed by\n    dgenerate, that pipeline will be used to process the inpainting done by adetailer. For a single\n    command line invocation you must use --post-processors to use this image processor correctly. In\n    dgenerate config script, you may use it anywhere, and the last executed diffusion pipeline will\n    be reused for inpainting.\n\n    Inpainting will occur on the device used by the last executed diffusion pipeline unless the\n    \"device\" argument is specified, the detector model can be run on an alternate GPU if desired\n    using the \"detector-device\" argument, otherwise the detector will run on \"device\".\n\n    Example:\n\n    --post-processors \"adetailer;\\\n    model=Bingsu/adetailer;\\\n    weight-name=face_yolov8n.pt;\\\n    prompt=detailed image of a mans face;\\\n    negative-prompt=nsfw, blurry, disfigured;\\\n    guidance-scale=7;\\\n    inference-steps=30;\\\n    strength=0.4\"\n\n    -----\n\n    The \"model\" argument specifies the YOLO detector model used to detect a feature of the image.\n\n    The \"prompt\" argument specifies the positive prompt to use for inpainting.\n\n    The \"negative-prompt\" argument specifies the negative prompt for inpainting.\n\n    The \"prompt-weighter\" argument specifies a prompt weighter plugin for applying prompt weighting\n    to the provided positive and negative prompts. Prompt weighters may have arguments, when\n    supplying URI arguments to a prompt weighter you must use double quoting around the prompt\n    weighter definition, i.e: --post-processors\n    \"adetailer;model=...;prompt=test;prompt-weighter='compel;syntax=sdwui'\"\n\n    The \"weight-name\" argument specifies the file name in a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument.\n\n    The \"subfolder\" argument specifies the subfolder in a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument.\n\n    The \"revision\" argument specifies the revision of a HuggingFace repository for the model\n    weights, if you have provided a HuggingFace repository slug to the model argument. For example:\n    \"main\"\n\n    The \"token\" argument specifies your HuggingFace authentication token explicitly if needed.\n\n    The \"local-files-only\" argument specifies that dgenerate should not attempt to download any\n    model files, and to only look for them locally in the cache or otherwise.\n\n    The \"seed\" argument can be used to specify a specific seed for diffusion when preforming\n    inpainting on the input image.\n\n    The \"inference-steps\" argument specifies the amount of inference steps when preforming\n    inpainting on the input image.\n\n    The \"guidance-scale\" argument specifies the guidance scale for inpainting.\n\n    The \"pag-scale\" argument indicates the perturbed attention guidance scale, this enables a PAG\n    inpaint pipeline if supported. If the previously used pipeline was a PAG pipeline, PAG is\n    automatically enabled for inpainting if supported and this value defaults to 3.0 if not\n    supplied. The adetailer processor supports PAG with --model-type torch and torch-sdxl.\n\n    The \"pag-adaptive-scale\" argument indicates the perturbed attention guidance adaptive scale,\n    this enables a PAG inpaint pipeline if supported. If the previously usee pipeline was a PAG\n    pipeline, PAG is automatically enabled for inpainting if supported and this value defaults to\n    0.0 if not supplied. The adetailer processor supports PAG with --model-type torch and\n    torch-sdxl.\n\n    The \"strength\" argument is analogous to --image-seed-strengths\n\n    The \"index-filter\" argument is a list values or a single value that indicates what YOLO\n    detection indices to keep, the index values start at zero. Detections are sorted by their top\n    left bounding box coordinate from left to right, top to bottom, by (confidence descending). The\n    order of detections in the image is identical to the reading order of words on a page (english).\n    Inpainting will only be preformed on the specified detection indices, if no indices are\n    specified, then inpainting will be preformed on all detections.\n\n    Example \"index-filter\" values:\n\n    # keep the first, leftmost, topmost detection\n    index-filter=0\n\n    # keep detections 1 and 3\n    index-filter=[1, 3]\n\n    # CSV syntax is supported (tuple)\n    index-filter=1,3\n\n    The \"detector-padding\" argument specifies the amount of padding that will be added to the\n    detection rectangle which is used to generate a masked area. The default is 0, you can make the\n    mask area around the detected feature larger with positive padding and smaller with negative\n    padding.\n\n    Padding examples:\n\n    32 (32px Uniform, all sides)\n\n    10x20 (10px Horizontal, 20px Vertical)\n\n    10x20x30x40 (10px Left, 20px Top, 30px Right, 40px Bottom)\n\n    The \"mask-padding\" argument indicates how much padding to place around the masked area when\n    cropping out the image to be inpainted. This value must be large enough to accommodate any\n    feathering on the edge of the mask caused by \"mask-blur\" or \"mask-dilation\" for the best result,\n    the default value is 32. The syntax for specifying this value is identical to\n    \"detector-padding\".\n\n    The \"mask-shape\" argument indicates what mask shape adetailer should attempt to draw around a\n    detected feature, the default value is \"rectangle\". You may also specify \"circle\" to generate an\n    ellipsoid shaped mask, which might be helpful for achieving better blending.\n\n    The \"mask-blur\" argument indicates the level of gaussian blur to apply to the generated inpaint\n    mask, which can help with smooth blending in of the inpainted feature\n\n    The \"mask-dilation\" argument indicates the amount of dilation applied to the inpaint mask, see:\n    cv2.dilate\n\n    The \"confidence\" argument can be used to adjust the confidence value for the YOLO detector\n    model. Defaults to: 0.3\n\n    The \"detector-device\" argument can be used to specify a device override for the YOLO detector,\n    i.e. the GPU / Accelerate device the model will run on. Example: cuda:0, cuda:1, cpu\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "anyline": {"gaussian-sigma": {"optional": false, "types": ["float"], "default": 2.0}, "intensity-threshold": {"optional": false, "types": ["int"], "default": 2}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "anyline:\n    arguments:\n        gaussian-sigma: float = 2.0\n        intensity-threshold: int = 2\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    anyline, MistoLine Control Every Line image preprocessor, see:\n    https://huggingface.co/TheMistoAI/MistoLine\n\n    This is an edge detector based on TEED.\n\n    The \"gaussian-sigma\" argument is the gaussian filter sigma value.\n\n    The \"intensity-threshold\" argument is the pixel value intensity threshold.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "canny": {"lower": {"optional": false, "types": ["int"], "default": 50}, "upper": {"optional": false, "types": ["int"], "default": 100}, "aperture-size": {"optional": false, "types": ["int"], "default": 3}, "L2-gradient": {"optional": false, "types": ["bool"], "default": false}, "blur": {"optional": false, "types": ["bool"], "default": false}, "gray": {"optional": false, "types": ["bool"], "default": false}, "threshold-algo": {"optional": true, "types": ["str"], "default": null}, "sigma": {"optional": false, "types": ["float"], "default": 0.33}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "canny:\n    arguments:\n        lower: int = 50\n        upper: int = 100\n        aperture-size: int = 3\n        L2-gradient: bool = False\n        blur: bool = False\n        gray: bool = False\n        threshold-algo: str | None = None\n        sigma: float = 0.33\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Process the input image with the Canny edge detection algorithm.\n\n    The \"lower\" argument indicates the lower threshold value for the algorithm, and the \"upper\"\n    argument indicates the upper threshold. \"aperture-size\" is the size of Sobel kernel used for\n    find image gradients, it must be an odd integer from 3 to 7. \"L2-gradient\" specifies the\n    equation for finding gradient magnitude, if True a more accurate equation is used. See:\n    https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html.\n\n    If \"blur\" is true, apply a 3x3 gaussian blur before processing. If \"gray\" is true, convert the\n    image to the cv2 \"GRAY\" format before processing, which does not happen automatically unless you\n    are using a \"threshold_algo\" value, OpenCV is capable of edge detection on colored images,\n    however you may find better results by converting to its internal grayscale format before\n    processing, or you may not, it depends.\n\n    If \"threshold_algo\" is one of (\"otsu\", \"triangle\", \"median\") try to calculate the lower and\n    upper threshold automatically using cv2.threshold or cv2.median in the case of \"median\". \"sigma\"\n    scales the range of the automatic threshold calculation done when a value for \"threshold_algo\"\n    is selected. \"pre-resize\" is a boolean value determining if the processing should take place\n    before or after the image is resized by dgenerate.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "flip": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "flip:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Flip the input image vertically.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "grayscale": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "grayscale:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Convert the input image to grayscale.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "hed": {"scribble": {"optional": false, "types": ["bool"], "default": false}, "safe": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "hed:\n    arguments:\n        scribble: bool = False\n        safe: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    HED detection (holistically-nested edge detection), this is an edge detection algorithm that can\n    produced something akin to thick lineart.\n\n    The \"scribble\" argument determines whether scribble mode is enabled, this produces thicker\n    lines.\n\n    The \"safe\" argument enables or disables numerically safe / more precise stepping.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect_resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "invert": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "invert:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Invert the colors of the input image.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "leres": {"threshold-near": {"optional": false, "types": ["int"], "default": 0}, "threshold-far": {"optional": false, "types": ["int"], "default": 0}, "boost": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "leres:\n    arguments:\n        threshold-near: int = 0\n        threshold-far: int = 0\n        boost: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    LeReS depth detector.\n\n    The \"threshold-near\" argument is the near threshold, think the low threshold of canny.\n\n    The \"threshold-far\" argument is the far threshold, think the high threshold of canny.\n\n    The \"boost\" argument determines if monocular depth boost is used.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "letterbox": {"box-size": {"optional": false, "types": ["str"]}, "box-is-padding": {"optional": false, "types": ["bool"], "default": false}, "box-color": {"optional": true, "types": ["str"], "default": null}, "inner-size": {"optional": true, "types": ["str"], "default": null}, "aspect-correct": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "letterbox:\n    arguments:\n        box-size: str\n        box-is-padding: bool = False\n        box-color: str | None = None\n        inner-size: str | None = None\n        aspect-correct: bool = True\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Letterbox an image.\n\n    The \"box-size\" argument is the size of the outer letterbox.\n\n    The \"box-is-padding\" argument can be used to indicate that \"box-size\" should be interpreted as\n    padding.\n\n    The \"box-color\" argument specifies the color to use for the letter box background, the default\n    is black. This should be specified as a HEX color code. e.g. #FFFFFF or #FFF\n\n    The \"inner-size\" argument specifies the size of the inner image.\n\n    The \"aspect-correct\" argument can be used to determine if the aspect ratio of the inner image is\n    maintained or not.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "lineart": {"course": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "lineart:\n    arguments:\n        course: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Line art generator, generate line art from an image.\n\n    The \"course\" argument determines whether to use the course model or the normal model.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "lineart-anime": {"detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "lineart-anime:\n    arguments:\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Anime line art generator, generate anime line art from an image.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "lineart-standard": {"gaussian-sigma": {"optional": false, "types": ["float"], "default": 6.0}, "intensity-threshold": {"optional": false, "types": ["int"], "default": 8}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "lineart-standard:\n    arguments:\n        gaussian-sigma: float = 6.0\n        intensity-threshold: int = 8\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Standard lineart detector, generate lineart from an image.\n\n    The \"gaussian-sigma\" argument is the gaussian filter sigma value.\n\n    The \"intensity-threshold\" argument is the pixel value intensity threshold.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "midas": {"normals": {"optional": false, "types": ["bool"], "default": false}, "alpha": {"optional": false, "types": ["float"], "default": 6.283185307179586}, "background-threshold": {"optional": false, "types": ["float"], "default": 0.1}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "midas:\n    arguments:\n        normals: bool = False\n        alpha: float = 6.283185307179586\n        background-threshold: float = 0.1\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    MiDaS depth detector and normal map generation.\n\n    The \"normals\" argument determines if this processor produces a normal map or a depth image.\n\n    The \"alpha\" argument is related to normal map generation.\n\n    The \"background_threshold\" argument is related to normal map generation.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "mirror": {"pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "mirror:\n    arguments:\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Mirror the input image horizontally.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "mlsd": {"threshold-score": {"optional": false, "types": ["float"], "default": 0.1}, "threshold-distance": {"optional": false, "types": ["float"], "default": 0.1}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "mlsd:\n    arguments:\n        threshold-score: float = 0.1\n        threshold-distance: float = 0.1\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Machine Learning Model for Detecting Wireframes. Wireframe edge detector, this processor\n    overlays lines on to the edges of objects in an image.\n\n    The \"threshold-score\" argument is the score threshold.\n\n    The \"threshold-distance\" argument is the distance threshold.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "normal-bae": {"detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "normal-bae:\n    arguments:\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Normal Bae Detector, generate a normal map from an image.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "openpose": {"include-body": {"optional": false, "types": ["bool"], "default": true}, "include-hand": {"optional": false, "types": ["bool"], "default": false}, "include-face": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "openpose:\n    arguments:\n        include-body: bool = True\n        include-hand: bool = False\n        include-face: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Generate an OpenPose rigging from the input image (of a human/humanoid) for use with a\n    ControlNet.\n\n    \"include-body\" is a boolean value indicating if a body rigging should be generated.\n\n    \"include-hand\" is a boolean value indicating if a detailed hand/finger rigging should be\n    generated.\n\n    \"include-face\" is a boolean value indicating if a detailed face rigging should be generated.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "pidi": {"apply-filter": {"optional": false, "types": ["bool"], "default": false}, "safe": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "pidi:\n    arguments:\n        apply-filter: bool = False\n        safe: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    PidiNet (Pixel Difference Networks for Efficient Edge Detection) edge detector.\n\n    The \"apply-filter\" argument enables possibly crisper edges / less noise.\n\n    The \"safe\" argument enables or disables numerically safe / more precise stepping.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "posterize": {"bits": {"optional": false, "types": ["int"]}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "posterize:\n    arguments:\n        bits: int\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Posterize the input image with PIL.ImageOps.posterize.\n\n    Accepts the argument 'bits', an integer value from 1 to 8.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "resize": {"size": {"optional": true, "types": ["str"], "default": null}, "scale": {"optional": true, "types": ["float", "tuple"], "default": null}, "align": {"optional": true, "types": ["int"], "default": null}, "aspect-correct": {"optional": false, "types": ["bool"], "default": true}, "algo": {"optional": false, "types": ["str"], "default": "auto"}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "resize:\n    arguments:\n        size: str | None = None\n        scale: float | tuple[float, float] | None = None\n        align: int | None = None\n        aspect-correct: bool = True\n        algo: str = \"auto\"\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Resize an image using basic resampling algorithms.\n\n    The \"size\" argument is the new image size.\n\n    The \"scale\" argument is either a single floating point value to scale both dimensions by, or a\n    tuple of two floating point values to scale x and y dimensions separately. This is mutually\n    exclusive with \"size\". When specifying a tuple, you may use CSV, for example: \"2,1\", meaning\n    X*2, Y*1.\n\n    The \"align\" argument is the new image alignment.\n\n    The \"aspect-correct\" argument is a boolean argument that determines if the resize is aspect\n    correct.\n\n    The \"algo\" argument is the resize filtering algorithm, which can be one of: \"auto\", \"nearest\",\n    \"box\", \"bilinear\", \"hamming\", \"bicubic\", \"lanczos\"\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "sam": {"detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "detect-align": {"optional": false, "types": ["int"], "default": 1}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "sam:\n    arguments:\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        detect-align: int = 1\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Segment Anything Model, this processor attempts to creates cutouts for every distinct objects in\n    an image.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect-resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"detect-align\" argument determines the pixel alignment of the image resize requested by\n    \"detect-resolution\", it defaults to 1 indicating no requested alignment.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "solarize": {"threshold": {"optional": false, "types": ["int"], "default": 128}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "solarize:\n    arguments:\n        threshold: int = 128\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Solarize the input image with PIL.ImageOps.solarize.\n\n    Accepts the argument \"threshold\" which is an integer value from 0 to 255.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "teed": {"safe": {"optional": false, "types": ["bool"], "default": true}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "teed:\n    arguments:\n        safe: bool = True\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    teed, a (tiny efficient edge detector).\n\n    The \"safe\" argument enables or disables numerically safe / more precise stepping.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "upscaler": {"model": {"optional": false, "types": ["str"]}, "tile": {"types": ["int", "str"], "default": 512}, "overlap": {"optional": false, "types": ["int"], "default": 32}, "scale": {"optional": true, "types": ["int"], "default": null}, "force-tiling": {"optional": false, "types": ["bool"], "default": false}, "dtype": {"optional": false, "types": ["str"], "default": "float32"}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "upscaler:\n    arguments:\n        model: str\n        tile: int | str = 512\n        overlap: int = 32\n        scale: int | None = None\n        force-tiling: bool = False\n        dtype: str = \"float32\"\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    Implements tiled upscaling with chaiNNer compatible upscaler models.\n\n    The \"model\" argument should be a path to a chaiNNer compatible upscaler model on disk, such as a\n    model downloaded from https://openmodeldb.info/, or an HTTP/HTTPS URL that points to a raw model\n    file.\n\n    For example:\n    \"upscaler;model=https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth\"\n\n    Downloaded models are cached in the dgenerate web cache on disk until the cache expiry time for\n    the file is met.\n\n    The \"tile\" argument can be used to specify the tile size for tiled upscaling, it must be\n    divisible by 2, and defaults to 512. Specifying 'auto' indicates that this value should be\n    calculated based off available GPU memory if applicable. Specifying 0 disables tiling entirely.\n\n    The \"overlap\" argument can be used to specify the overlap amount of each tile in pixels, it must\n    be greater than or equal to 0, and defaults to 32.\n\n    The \"scale\" argument can be used to specify the output scale of the image regardless of the\n    models scale, this equates to an image resize on each tile output of the model as necessary,\n    with auto selected resizing algorithm for the best quality. This is effectively equivalent to\n    basic image resizing of the upscaled output post upscale, just with somewhat reduced memory\n    overhead as it occurs during tiling. When this argument is not specified, the scale of the model\n    architecture is used and no resizing occurs. This argument must be greater than or equal to 1.\n\n    The \"force-tiling\" argument can be used to force external image tiling for upscaler model\n    architectures which discourage the use of external tiling (SCUNEt and MixDehazeNet currently),\n    this may mean that the model needs information about the whole image to achieve a good result.\n    External tiling breaks up the image into tiles before feeding it to the model and reassembles\n    the images output by the model, this is not the default behavior when a model specifies that\n    tiling is discouraged, tiling is only on by default for models where external tiling is fully\n    supported. Only use this if you run into memory issues with models that discourage external\n    tiling, in the case that the model discourages its use, using it may result in substandard image\n    output.\n\n    The \"dtype\" argument can be used to specify the datatype to use to for the model in memory, it\n    can be either \"float32\" or \"float16\". Using \"float16\" will result in a smaller memory footprint\n    if supported.\n\n    The \"pre-resize\" argument is a boolean value determining if the processing should take place\n    before or after the image is resized by dgenerate.\n\n    Example: \"upscaler;model=my-model.pth;tile=256;overlap=16\"\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}, "upscaler-ncnn": {"model": {"optional": false, "types": ["str"]}, "param": {"optional": false, "types": ["str"]}, "use-gpu": {"optional": false, "types": ["bool"], "default": false}, "gpu-index": {"optional": false, "types": ["int"], "default": 0}, "threads": {"types": ["int", "str"], "default": "auto"}, "blocktime": {"optional": true, "types": ["int"], "default": null}, "winograd": {"optional": true, "types": ["bool"], "default": null}, "sgemm": {"optional": true, "types": ["bool"], "default": null}, "tile": {"optional": false, "types": ["int"], "default": 400}, "overlap": {"optional": false, "types": ["int"], "default": 8}, "scale": {"optional": true, "types": ["int"], "default": null}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "upscaler-ncnn:\n    arguments:\n        model: str\n        param: str\n        use-gpu: bool = False\n        gpu-index: int = 0\n        threads: int | str = \"auto\"\n        blocktime: int | None = None\n        winograd: bool | None = None\n        sgemm: bool | None = None\n        tile: int = 400\n        overlap: int = 8\n        scale: int | None = None\n        pre-resize: bool = False\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n\n    Implements tiled upscaling with NCNN upscaler models.\n\n    The \"model\" argument should be a path or URL to a NCNN compatible upscaler model.\n\n    The \"param\" argument should be a path or URL to the NCNN param file for the model.\n\n    Downloaded model / param files are cached in the dgenerate web cache on disk until the cache\n    expiry time for the file is met.\n\n    When using this processor as a pre-processor or post-processor for diffusion, GPU memory will be\n    fenced, any cached models related to diffusion on the GPU will be evacuated entirely before this\n    processor runs if they exist on the same GPU as the processor, this is to prevent catastrophic\n    interaction between the Vulkan and Torch cuda allocators.\n\n    Once a Vulkan allocator exists on a specific GPU it cannot be destroyed except via the process\n    exiting due to issues with the ncnn python binding. If you create this processor on a GPU you\n    intend to perform diffusion on, you are going to run into memory errors after the first image\n    generation and there on out until the process exits.\n\n    When the process exits it is very likely to exit with a non-zero return code after using this\n    processor even if the upscale operations were successful, this is due to problems with the ncnn\n    python binding creating a segfault at exit. If you are using dgenerate interactively in shell\n    mode or from the Console UI, this will occur without consequence when the interpreter process\n    exits.\n\n    Note that if any other process runs diffusion / inference via torch on the same GPU as this\n    image processor while ncnn is preforming inference, you will likely encounter a segfault in\n    either of the processes and a very hard crash.\n\n    You can safely run this processor in parallel with diffusion, or other torch based image\n    processors with GPU acceleration, by placing it on a separate gpu using the \"gpu-index\"\n    argument.\n\n    For these reasons, this processor runs on the CPU by default, you can enable GPU usage with GPU\n    related arguments mentioned in this documentation below.\n\n    -----\n\n    The \"use-gpu\" argument determines if the gpu is used, defaults to False.\n\n    The \"gpu-index\" argument determines which gpu is used, it is 0 indexed, and defaults to 0 which\n    is most likely your main GPU.\n\n    The \"threads\" argument determines the number of cpu threads used, the default value is \"auto\"\n    which uses the maximum amount. You may also pass \"half\" to use half the cpus logical thread\n    count.\n\n    The \"blocktime\" argument determines the blocktime in milliseconds for OpenMP parallelization\n    when running on the cpu, this value should be between 0 and 400 milliseconds, if you do not\n    specify the NCNN default for your platform is used. You cannot use this argument when running on\n    the GPU, an argument error will be thrown.\n\n    The \"winograd\" argument determines if the winograd convolution optimization is used when running\n    on the CPU. If you do not specify it, the NCNN default for you platform is used. You cannot use\n    this argument when running on the GPU, an argument error will be thrown.\n\n    The \"sgemm\" argument determines if the sgemm convolution optimization is used when running on\n    the CPU. If you do not specify it, the NCNN default for you platform is used. You cannot use\n    this argument when running on the GPU, an argument error will be thrown.\n\n    The \"tile\" argument can be used to specify the tile size for tiled upscaling, it must be\n    divisible by 2 and be less than or equal to 400, the default is 400. Tile size is limited to a\n    max of 400 due to memory allocator issues in ncnn. You may disable tiling by setting \"tile=0\"\n    however, you can only do this for images under 400 pixels in both dimensions, if the image is\n    over 400 pixels in any dimension, and you disabled tiling, a usage error will be thrown.\n\n    The \"overlap\" argument can be used to specify the overlap amount of each tile in pixels, it must\n    be greater than or equal to 0, and defaults to 8.\n\n    The \"scale\" argument can be used to specify the output scale of the image regardless of the\n    models scale, this equates to an image resize on each tile output of the model as necessary,\n    with auto selected resizing algorithm for the best quality. This is effectively equivalent to\n    basic image resizing of the upscaled output post upscale, just with somewhat reduced memory\n    overhead as it occurs during tiling. When this argument is not specified, the scale of the model\n    architecture is used and no resizing occurs. This argument must be greater than or equal to 1.\n\n    The \"pre-resize\" argument is a boolean value determining if the processing should take place\n    before or after the image is resized by dgenerate.\n\n    x4.bin: https://github.com/nihui/realsr-ncnn-vulkan/blob/master/models/models-DF2K/x4.bin\n    x4.param: https://github.com/nihui/realsr-ncnn-vulkan/blob/master/models/models-DF2K/x4.param\n\n    Example: \"upscaler-ncnn;model=x4.bin;param=x4.param;tile=256;overlap=16;use-gpu=True\"\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten."}, "zoe": {"gamma-corrected": {"optional": false, "types": ["bool"], "default": false}, "detect-resolution": {"optional": true, "types": ["str"], "default": null}, "detect-aspect": {"optional": false, "types": ["bool"], "default": true}, "pre-resize": {"optional": false, "types": ["bool"], "default": false}, "device": {"optional": true, "types": ["str"], "default": null}, "output-file": {"optional": true, "types": ["str"], "default": null}, "output-overwrite": {"optional": false, "types": ["bool"], "default": false}, "model-offload": {"optional": false, "types": ["bool"], "default": false}, "PROCESSOR_HELP": "zoe:\n    arguments:\n        gamma-corrected: bool = False\n        detect-resolution: str | None = None\n        detect-aspect: bool = True\n        pre-resize: bool = False\n        device: str | None = None\n        output-file: Optional[str] = None\n        output-overwrite: bool = False\n        model-offload: bool = False\n\n    zoe depth detector, a SOTA depth estimation model which produces high-quality depth maps.\n\n    The \"gamma-corrected\" argument determines if gamma correction is preformed on the produced depth\n    math.\n\n    The \"detect-resolution\" argument is the resolution the image is resized to internal to the\n    processor before detection is run on it. It should be a single dimension for example:\n    \"detect-resolution=512\" or the X/Y dimensions seperated by an \"x\" character, like so:\n    \"detect-resolution=1024x512\". If you do not specify this argument, the detector runs on the\n    input image at its full resolution. After processing the image will be resized to whatever you\n    have requested dgenerate resize it to via --output-size or --resize/--align in the case of the\n    image-process sub-command, if you have not requested any resizing the output will be resized\n    back to the original size of the input image.\n\n    The \"detect-aspect\" argument determines if the image resize requested by \"detect_resolution\"\n    before detection runs is aspect correct, this defaults to true.\n\n    The \"pre-resize\" argument determines if the processing occurs before or after dgenerate resizes\n    the image. This defaults to False, meaning the image is processed after dgenerate is done\n    resizing it.\n\n    The \"device\" argument can be used to set the device the processor will run on, for example: cpu,\n    cuda, cuda:1. If you are using this image processor as a preprocess or postprocess step for\n    dgenerate, or with the image-process subcommand, or \\image_process directive, this argument will\n    default to the value of --device.\n\n    The \"output-file\" argument can be used to set the output path for a processor debug image, this\n    will save the processed image to a path of your choosing.\n\n    The \"output-overwrite\" argument can be used to enable overwrite for a processor debug image. If\n    this is not enabled, new images written by the processor while it is being used will be written\n    with a numbered suffix instead of being overwritten.\n\n    The \"model-offload\" argument can be used to enable cpu model offloading for a processor. If this\n    is disabled, any torch tensors or modules placed on the GPU will remain there until the\n    processor is done being used, instead of them being moved back to the CPU after each image.\n    Enabling this may help save VRAM when using an image processor as a preprocessor or\n    postprocessor for diffusion with dgenerate but will impact rendering speed when generating many\n    images."}}