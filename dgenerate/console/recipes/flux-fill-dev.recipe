title: Flux Fill (Dev)
order: 17

# Flux requires a huggingface auth token to access
# you must request access to the repository

\setp auth_token "@string[{"label": "Hugging Face Auth Token", "default":"$HF_TOKEN", "optional":false}]"

\set auth_token {{ '--auth-token ' + quote(auth_token) if auth_token else '' }}

@uri[{"label":"Model Path / HF Slug", "dir":true, "default": "black-forest-labs/FLUX.1-Fill-dev", "optional":false, "file-types":["models"]}]
--model-type torch-flux-fill {{ auth_token }}
@dropdown[{"label":"Model dtype", "arg":"--dtype", "options":["float16", "bfloat16", "float32"], "default":"bfloat16"}]
@karrasscheduler[{"label":"Scheduler", "arg":"--scheduler", "filter": ["FlowMatchEulerDiscreteScheduler"]}]
@checkboxwithfloatarg[{"label":"Use TeaCache", "arg":"--tea-cache", "default":false, "float-arg":"--tea-cache-rel-l1-thresholds", "float-label":"TeaCache L1 Threshold", "float": 0.6, "min":0.0, "max":1.0}]
@switchradio[{"labels":["Model CPU Offload", "Model Sequential Offload"], "args":["--model-cpu-offload", "--model-sequential-offload"], "default":1}]
@quantizer[{"divider-after":true}]
@torchvae[{"label":"VAE Path / URI", "dir":true, "file-types":["models"]}]
@switch[{"label":"VAE Tiling", "arg":"--vae-tiling"}]
@switch[{"label":"VAE Slicing", "arg":"--vae-slicing", "divider-after":true}]
@uriwithfloat[{"label":"LoRA Path / URI", "float-label":"LoRA Scale", "arg":"--loras", "float-arg":"scale", "dir":true, "file-types":["models"]}]
@uri[{"label":"Transformer Path / URI", "dir":true, "arg":"--transformer", "file-types":["models"], "divider-after":true}]
--image-seeds @file[{"label":"Input Image File", "optional":false, "mode":"input", "file-types":["images-in", "videos-in"]}];@file[{"label":"Input Mask File", "optional":false, "mode":"input", "file-types":["images-in", "videos-in"]}]
@switch[{"label":"No Aspect Correction?", "arg":"--no-aspect"}]
@imageprocessor[{"arg":"--seed-image-processors", "label":"Seed Image Processor"}]
@imageprocessor[{"arg":"--mask-image-processors", "label":"Inpaint Mask Processor"}]
@int[{"label":"Inference Steps", "arg":"--inference-steps", "default":50, "min":1}]
@float[{"label":"Guidance Scale", "arg":"--guidance-scales", "default":3.5, "min":0}]
@seeds[{"label":"Seeds"}]
@int[{"label":"Batch Size", "arg":"--batch-size", "default":"", "min":1}]
@imagesize[{"label":"Batch Grid Size (CxR)", "arg":"--batch-grid-size", "default":"", "divider-after":true}]
@dir[{"label":"Output Directory", "arg":"--output-path", "default":"output"}]
@imagesize[{"label":"Output Size (WxH)", "arg":"--output-size", "default":"1024x1024"}]
@promptupscaler[{"label":"Prompt Upscaler", "arg":"--prompt-upscaler"}]
@promptweighter[{"label":"Prompt Weighter", "arg":"--prompt-weighter", "filter":["sd-embed"]}]
@imageprocessor[{"arg":"--post-processors", "label":"Post Processor"}]
@device[{}]
--prompts "add your prompt here"