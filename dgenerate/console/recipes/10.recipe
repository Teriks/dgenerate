title: Deep Floyd

# DeepFloyd requires a multistage generation process involving 
# multiple models and more advanced use of dgenerate

# You need a huggingface account (http://huggingface.co) and to 
# request access to the models at (https://huggingface.co/DeepFloyd) 
# in order for dgenerate to be able to download the required models

# once you have done this, provide your access token 
# from (https://huggingface.co/settings/tokens)

# Or set the environmental variable HF_TOKEN on your system

\set prompt "add your prompt here"

\setp auth_token "@string[{"label": "Hugging Face Auth Token", "default":"$HF_TOKEN", "optional":false}]"

\set device @device[{"optional":false}]

\set output_dir @dir[{"label":"Output Directory", "arg":"--output-path", "default":"output", "optional":false, "divider-after":true}]

\set auth_token {{ '--auth-token ' + quote(auth_token) if auth_token else '' }}

@uri[{"label":"Stage 1 Model Path / HF Slug", "default": "DeepFloyd/IF-I-M-v1.0", "optional":false, "dir":true, "file-types":["models"]}]
@karrasscheduler[{"label":"Stage 1 Scheduler", "filter": ["DDPMScheduler"]}]
--variant fp16
--dtype float16
--model-type torch-if
--model-sequential-offload
@int[{"label":"Stage 1 Inference Steps", "arg":"--inference-steps", "default":60, "min":1}]
@float[{"label":"Stage 1 Guidance Scale", "arg":"--guidance-scales", "default":7, "min":0}]
--output-size 64
@seeds[{"label":"Seeds", "divider-after":true}]
--prompts {{ prompt }}
--output-prefix stage1 {{ device }} {{ output_dir }} {{ auth_token }}

\save_modules stage_1_modules feature_extractor

@uri[{"label":"Stage 2 Model Path / HF Slug", "default": "DeepFloyd/IF-II-M-v1.0", "optional":false, "dir":true, "file-types":["models"]}]
@karrasscheduler[{"label":"Stage 2 Scheduler", "filter": ["DDPMScheduler"]}]
--variant fp16
--dtype float16
--model-type torch-ifs
--model-sequential-offload
@int[{"label":"Stage 2 Inference Steps", "arg":"--inference-steps", "default":30, "min":1}]
@float[{"label":"Stage 2 Guidance Scale", "arg":"--guidance-scales", "default":4, "min":0}]
@int[{"label":"Stage 2 Upscaler Noise Level", "arg":"--upscaler-noise-levels", "default":250, "min":1, "divider-after":true}]
--prompts {{ format_prompt(last_prompts) }}
--seeds {{ last_seeds | join(' ') }}
--seeds-to-images
--image-seeds {{ quote(last_images) }}
--output-prefix stage2 {{ device }} {{ output_dir }} {{ auth_token }}

\use_modules stage_1_modules

@uri[{"label":"Stage 3 - x4 Upscaler Model Path / HF Slug", "default": "stabilityai/stable-diffusion-x4-upscaler", "optional":false, "dir":true, "file-types":["models"]}]
--variant fp16
--dtype float16
--model-type torch-upscaler-x4
@karrasscheduler[{"label":"Stage 3 Scheduler"}]
@torchvae[{"label":"Stage 3 VAE File / URI", "dir":true, "file-types":["models"]}]
@int[{"label":"Stage 3 Inference Steps", "arg":"--inference-steps", "default":30, "min":1}]
@float[{"label":"Stage 3 Guidance Scale", "arg":"--guidance-scales", "default":9, "min":0}]
--prompts {{ format_prompt(last_prompts) }}
--seeds {{ last_seeds | join(' ') }}
--seeds-to-images
--image-seeds {{ quote(last_images) }}
@int[{"label":"Stage 3 Upscaler Noise Level", "arg":"--upscaler-noise-levels", "default":20, "min":1, "divider-after":true}]
@imageprocessor[{"arg":"--post-processors", "label":"Post Processor"}]
--output-prefix stage3 {{ device }} {{ output_dir }} {{ auth_token }}

\clear_modules stage_1_modules