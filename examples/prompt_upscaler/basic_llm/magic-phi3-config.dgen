#! /usr/bin/env dgenerate --file
#! dgenerate 5.0.0

# Use Phi-3 abliterated as a prompt text enhancer

# Any LLM that transformers can run, can be used.

# The "preamble" text is inserted at the beginning of your prompt, and then removed from the LLMs output

# This is less sophisticated than using the "system" argument of the magicprompt plugin to add a
# system instruction to the prompt, but seems to work well for this model (sometimes)
# You can try tweaking "preamble" or "system" to achieve better results, though a "system"
# prompt has a high chance of generating rejection responses

# Set a seed for consistent LLM output across prompt variations

# Use dynamicprompts before the magicprompt plugin to generate combinatorial variations using dynamicprompts syntax

{% if have_cuda() and have_feature('bitsandbytes') %}
    \set llm_optimization ;quantizer='bnb;bits=8'
{% endif %}

\set llm_model 'failspy/Phi-3-mini-128k-instruct-abliterated-v3'

\set llm_preamble 'Enhance this photo description:'

\set llm_seed 32


stabilityai/stable-diffusion-xl-base-1.0
--model-type sdxl
--dtype float16
--variant fp16
--inference-steps 30
--guidance-scales 5
--clip-skips 0
--gen-seeds 1
--output-path magic-phi3
--output-size 1024x1024
--prompt-weighter sd-embed
--prompt-upscaler dynamicprompts magicprompt;model={{ llm_model }};preamble={{ llm_preamble }};seed={{ llm_seed }}{{ llm_optimization }}
--prompts "a {horse|cow|dog} in a field on a cloudy day in the mountains"