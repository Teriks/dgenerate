#! /usr/bin/env dgenerate --file
#! dgenerate 4.2.1

\set token %HF_TOKEN%

{% if not token.strip() and not '--auth-token' in injected_args %}
    \print Set HF_TOKEN environmental variable or --auth-token to run this example!
    \exit
{% endif %} !END
    
# this model will load all three text encoders,
# they are not cached individually as we did not explicitly
# specify any of them, they are cached with the pipeline
# as a whole

stabilityai/stable-diffusion-3-medium-diffusers
--model-type torch-sd3
--variant fp16
--dtype float16
--inference-steps 30
--guidance-scales 5.00
--clip-skips 0
--gen-seeds 2
--output-path share_encoders
--model-sequential-offload
--prompts "a horse outside a barn"

# store all the text encoders from the last pipeline
# into the variable "encoders"

\save_modules encoders text_encoder text_encoder_2 text_encoder_3

# share them with the next pipeline

\use_modules encoders

# use all of the encoders except the T5 encoder (third encoder)
# sharing modules this way saves a significant amount 
# of memory

stabilityai/stable-diffusion-3-medium-diffusers
--model-type torch-sd3
--variant fp16
--dtype float16
--inference-steps 30
--guidance-scales 5.00
--clip-skips 0
--text-encoders + + null 
--gen-seeds 2
--output-path share_encoders
--model-sequential-offload
--prompts "a horse outside a barn"