#! /usr/bin/env dgenerate --file
#! dgenerate 4.4.2

\set token %HF_TOKEN%

{% if not token.strip() and not '--auth-token' in injected_args %}
    \print Set HF_TOKEN environmental variable or --auth-token to run this example!
    \exit
{% endif %} !END


# We can run this same prompt over multiple images in batch on the GPU
# by using the "images: ..." syntax of --image-seeds

# here we are using inpainting, we can specify a mask associated with
# each input image individually if we wanted, but only one is specified,
# so it is used with ever input image.

# all images involved must be the same dimension or resized to the same dimension

# Two images are produced on the GPU in once go, --vae-tiling and --vae-slicing
# is used to reduce memory usage upon VAE decode

# The first image will yield a cat on a bench, and the second will have a cat
# on a very squashed image of a beach

# If we wanted we could use --batch-grid-size to put these images into a grid

stabilityai/stable-diffusion-3-medium-diffusers
--model-type torch-sd3
--variant fp16
--dtype float16
--inference-steps 30
--guidance-scales 8
--image-seeds "images: ../../media/dog-on-bench.png, ../../media/beach.jpg;mask=../../media/dog-on-bench-mask.png;resize=1024;aspect=False"
--image-seed-strengths 1
--vae-tiling
--vae-slicing
--output-path batching
--model-sequential-offload
--prompts "A fluffy orange cat, realistic, high quality; deformed, scary"
