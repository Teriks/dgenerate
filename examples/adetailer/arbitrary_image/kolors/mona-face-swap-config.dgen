#! /usr/bin/env dgenerate --file
#! dgenerate 4.5.1

# You can use any Kolors model you want in combination with the adetailer inpainting algorithm
# this can be preformed on any image of your choosing in this manner

# This can be used for highly configurable face detailing on diffusion output, or
# for face swapping and other interesting effects

# In this example we can attempt to face swap the monalisa with a little help from
# the SDXL depth ControlNet to orient the new face in the correct direction.
# This works because ControlNets are compatible with SDXL inpainting

# we generate a depth image from the incoming control image using the midas image processor

# --adetailer-crop-control-image tells the adetailer algorithm to crop the depth
# image down to just the detection area, so that its just the face depth map
# that is used as the control image

# we specify --adetailer-detectors with a model that detects faces, an inpaint
# mask will be auto generated around the face and then inpainting will occur
# with the controlnet active

# The generated inpaint masks properties can be adjusted with: --adetailer-mask-paddings,
# --adetailer-mask-blurs, and --adetailer-mask-dilations. These arguments are plural because
# they can accept multiple values, when you provide multiple values dgenerate will
# create multiple variations of the image with those values.

Kwai-Kolors/Kolors-diffusers
--model-type torch-kolors
--variant fp16
--dtype float16
--image-seeds ../../../media/monalisa.png;control=../../../media/monalisa.png
--inference-steps 30
--guidance-scales 7
--control-nets Kwai-Kolors/Kolors-ControlNet-Depth;scale=0.6
--control-image-processors midas
--adetailer-detectors Bingsu/adetailer;weight-name=face_yolov8n.pt
--adetailer-crop-control-image
--adetailer-mask-blurs 32
--adetailer-detector-paddings 20
--image-seed-strengths 0.5
--seeds 1
--model-sequential-offload
--output-size 800
--output-path face-swap-mona
--prompts "woman smiling really wide and showing teeth; deformed, weird chin"