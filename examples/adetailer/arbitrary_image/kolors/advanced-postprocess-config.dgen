#! /usr/bin/env dgenerate --file
#! dgenerate 5.0.0

# first we should generate an image that we want to refine
# with adetailer using some model, or operation that affects
# the last_images template variable, even \image_process will
# do this


\setp can_quant have_cuda() and have_feature('bitsandbytes')
\setp total_vram total_memory(unit='gib')

{% if can_quant and total_vram > 15 %}
    \set optimization --quantizer bnb;bits=4
{% elif can_quant and total_vram > 10 %}
    \set optimization --quantizer bnb;bits=4;bits4-quant-type=nf4;bits4-use-double-quant=True
{% else %}
    \set optimization --model-sequential-offload
{% endif %}


Kwai-Kolors/Kolors-diffusers
--model-type torch-kolors {{ optimization }}
--dtype float16
--variant fp16
--inference-steps 30
--guidance-scales 7
--gen-seeds 1
--output-path advanced-postprocess
--output-prefix unrefined
--output-size 1024
--prompts "full body photo of emma watson in black clothes, \
           night city street, bokeh; pencil drawing, black and white, \
           greyscale, poorly drawn, bad anatomy, wrong anatomy, extra limb, \
           missing limb, floating limbs, disconnected limbs, mutation, mutated, \
           ugly, disgusting, amputation"


# make every image from the last generation an --image-seeds value
# that gets passed to the adetailer step, the settings
# for the adetailer process are far more configurable this
# way, but this cannot be done as a one liner on the command
# line as with --post-processors

# we can for instance, use the combinatorial arguments of dgenerate
# to make variations, and also run the SDXL refiner as a final step,
# where as with --post-processors, the SDXL refiner always runs before
# adetailer

# we can also choose any model type and model that we want to use with
# adetailer, even different models than the model that generated the initial image,
# as long as that model supports inpainting

# this means we can apply this postprocess to the output of models that do not
# support adetailer if desired, such as Stable Cascade etc.

# now, combinatorially refine 8 variants using different settings for adetailer
# so that we can observe differences in the output

Kwai-Kolors/Kolors-diffusers
--model-type torch-kolors {{ optimization }}
--variant fp16
--dtype float16
--image-seeds {{ quote(last_images) }}
--inference-steps 30
--guidance-scales 7
--adetailer-detectors Bingsu/adetailer;weight-name=face_yolov8n.pt
--adetailer-mask-blurs 4 8
--adetailer-mask-dilations 4 8
--image-seed-strengths 0.4 0.7
--output-path advanced-postprocess
--output-prefix refined
--prompts "image of emma watson; nsfw, blurry, disfigured"